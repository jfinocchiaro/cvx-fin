\documentclass[12pt]{colt2021} %% Anonymized submission
      \usepackage{times}
      \usepackage{lmodern}
      \usepackage{hyperref}       % hyperlinks  %[implicit=false, bookmarks=false]
      \usepackage{booktabs}       % professional-quality tables
      \usepackage{amsfonts}       % blackboard math symbols
      \usepackage{nicefrac}       % compact symbols for 1/2, etc.
      \usepackage{microtype}      % microtypography
      
      \PassOptionsToPackage{numbers, sort, compress}{natbib}
      
      \usepackage{mathtools, verbatim}
      %\usepackage[thmmarks, thref, amsthm]{ntheorem}
      \usepackage{color}
      \definecolor{darkblue}{rgb}{0.0,0.0,0.2}
      \hypersetup{colorlinks,breaklinks,
      	linkcolor=darkblue,urlcolor=darkblue,
      	anchorcolor=darkblue,citecolor=darkblue}
      \usepackage{wrapfig}
      \usepackage[small]{caption}
      % NOTE: had to comment out "todo" in colt2021.cls
      \usepackage[colorinlistoftodos,textsize=tiny]{todonotes} % need xargs for below
      %\usepackage{accents}
      \usepackage{bbm}
      \usepackage{xspace}
      \usetikzlibrary{arrows}
      \usetikzlibrary{shapes}
      
      \makeatletter
      \let\Ginclude@graphics\@org@Ginclude@graphics 
      \makeatother
      
      %\usetikzlibrary{calc}
      \newcommand{\Comments}{0}
      \newcommand{\mynote}[2]{\ifnum\Comments=1\textcolor{#1}{#2}\fi}
      \newcommand{\mytodo}[2]{\ifnum\Comments=1%
      	\todo[linecolor=#1!80!black,backgroundcolor=#1,bordercolor=#1!80!black]{#2}\fi}
      \newcommand{\raf}[1]{\mynote{green}{[RF: #1]}}
      \newcommand{\raft}[1]{\mytodo{green!20!white}{RF: #1}}
      \newcommand{\jessie}[1]{\mynote{purple}{[JF: #1]}}
      \newcommand{\jessiet}[1]{\mytodo{purple!20!white}{JF: #1}}
      \newcommand{\bo}[1]{\mynote{blue}{[Bo: #1]}}
      \newcommand{\botodo}[1]{\mytodo{blue!20!white}{[Bo: #1]}}
      \newcommand{\btw}[1]{}%\mytodo{orange!80!white}{BTW: #1}}
      \newcommand{\discuss}[1]{\mynote{cyan!20!white}{#1}}
      \ifnum\Comments=1               % fix margins for todonotes
      \setlength{\marginparwidth}{1in}
      \fi
      
      \newcommand{\reals}{\mathbb{R}}
      \newcommand{\posreals}{\reals_{>0}}%{\reals_{++}}
      \newcommand{\simplex}{\Delta_\Y}
      \newcommand{\relint}[1]{\mathrm{relint}(#1)}
      \newcommand{\interior}{\mathrm{int}\,}
      \newcommand{\prop}[2][\mathcal{P}]{\mathrm{prop}_{#1}[#2]}
      \newcommand{\elic}{\mathrm{elic}}
      \newcommand{\eliccvx}{\mathrm{elic}_\mathrm{cvx}}
      \newcommand{\conscvx}{\mathrm{cons}_\mathrm{cvx}}
      \newcommand{\elicpoly}{\mathrm{elic}_\mathrm{pcvx}}
      \newcommand{\elicembed}{\mathrm{elic}_\mathrm{embed}}
      \newcommand{\ccdim}{\mathrm{cc\,dim}}
      \newcommand{\rank}{\mathrm{rank}}
      \newcommand{\proj}{\mathrm{proj}}
      \newcommand{\supp}{\mathrm{supp}}
      \newcommand{\spn}{\mathrm{span}}
      
      \newcommand{\range}{\mathrm{range}\,}
      \newcommand{\zeros}[1]{\mathrm{ker}_\P\,#1}
      \newcommand{\codim}{\mathrm{codim}}
      \newcommand{\Pcodim}{\mathcal{P}\!\text{-}\mathrm{codim}}
      \newcommand{\Pcodimension}{$\mathcal{P}$-codimension\,}
      
      \newcommand{\propdis}{\mu}
      \newcommand{\affhull}{\mathrm{affhull}}
      \newcommand{\epi}{\mathrm{epi}}
      \newcommand{\cl}{\mathbf{cl}}
      %\newcommand{\span}{\mathrm{span}}
      
      \newcommand{\A}{\mathcal{A}}
      \newcommand{\C}{\mathcal{C}}
      \newcommand{\D}{\mathcal{D}}
      \newcommand{\E}{\mathbb{E}}
      \newcommand{\F}{\mathcal{F}}
      \renewcommand{\L}{\mathcal{L}}
      \newcommand{\Lcvx}{\mathcal{L}^{\mathrm{cvx}}}
      \newcommand{\I}{\mathcal{I}}
      \newcommand{\N}{\mathcal{N}}
      \newcommand{\R}{\mathcal{R}}
      \renewcommand{\P}{\mathcal{P}}
      \newcommand{\Sc}{\mathcal{S}}  % jessie, feel free to redef, just not \S :-)
      \newcommand{\Scr}{\mathcal{S}}  % using this for the span of F_p - not sure if we want this to be parallel to the feasible subspace notation
      \newcommand{\U}{\mathcal{U}}
      \newcommand{\V}{\mathcal{V}}
      \newcommand{\X}{\mathcal{X}}
      \newcommand{\Y}{\mathcal{Y}}
      
      
      \newcommand{\ellbar}{\underline{\ell}}
      \newcommand{\lbar}{\underline{L}} % couldn't do L* while proofreading...
      \newcommand{\iden}{\mathrm{iden}}
      \newcommand{\im}{\mathrm{im}}
      \newcommand{\Var}{\mathrm{Var}}
      \newcommand{\CVaR}{\mathrm{CVaR}}
      
      \newcommand{\exploss}[3]{\E_{#3} #1(#2,Y)}
      \newcommand{\risk}[1]{\underline{#1}}
      \newcommand{\Ind}[1]{\mathbf{I}\{{#1}\}}
      \newcommand{\inprod}[2]{\langle #1, #2 \rangle}
      \newcommand{\toto}{\rightrightarrows}
      \newcommand{\ones}{\mathbbm{1}}
      
      %\newtheorem{theorem}{Theorem}
      %\newtheorem{lemma}{Lemma}
      %\newtheorem{proposition}{Proposition}
      %\newtheorem{corollary}{Corollary}
      %\newtheorem{conjecture}{Conjecture}
      %\newtheorem{definition}{Definition}
      \newtheorem{assumption}{Assumption}
      \newtheorem{condition}{Condition}
      %\newtheorem{remark}{Remark}
      
      
      \DeclareMathOperator*{\argmax}{arg\,max}
      \DeclareMathOperator*{\argmin}{arg\,min}
      \DeclareMathOperator*{\arginf}{arg\,inf}
      \DeclareMathOperator*{\sgn}{sgn}
      
      \usepackage{thmtools, thm-restate}
      %\declaretheorem{corollary}
      
      \begin{document}
      \title{}                     %% This removes title for more space 
      
We thank the reviewers for their thoughtful comments.  On novelty of our results: We provide novel contributions both to specific elicitation/consistency bounds of interest (in Quadrant 4, not Quadrant 1 where reviewers seemed to focus), and conceptually to the broader literature on consistency of surrogate losses.  We outline both of these contributions below, and would urge the reviewers to consider both.

\paragraph{Novel bounds: Bayes risks and other risk measures}  
Our paper resolves an open question posed by Frongillo-Kash (NeurIPS 2015), on developing bounds for elicitation complexity for continuous estimation problems (Quadrants 3 and 4) with respect to convex surrogates.  (Our other novel bounds are mainly to illustrate the power of the tools, as we discuss below.)  Specifically, we show the first bounds on elicitation complexity of risk measures with respect to convex losses.  While the tools we use to show these bounds are heavily inspired by ideas in prior works, they required original and careful adaptation at every level; see Section 6 and Appendix C.

\paragraph{Conceptual: broader, easier, and stronger tool}  While our techniques draw inspiration from Ramaswamy-Agarwal (2016) and Agarwal-Agarwal (2015), we provide a significant conceptual contribution.  Specifically, we give a general tool to reason about consistency, which is:  (1) \underline{Broader}: the above works' definitions and results are tailored to Quadrant 1 (discrete, given target loss), while our tool applies to all 4 quadrants.  (2) \underline{Easier}: AA15 ``lifts'' property elicitation up to calibration, whereas we ``pull'' calibration down to elicitation, which is simpler to work with, as one need only reason about exact minimizers of expected loss rather than approximate minimizers.  We believe researchers will find this approach significantly simpler to conceptualize and apply.  Yet surprisingly, it is: (3) \underline{Stronger}: our example lower bound for abstain loss is stronger than what can be obtained via previous tools, namely feasible subspace dimension (FSD).  This extra strength stems from the fact that FSD relies only on local information (in the probability simplex), whereas we look at global information.  The combination of (1,2,3) is exactly what allowed us to prove the novel bounds for risk measures above.

\vspace{-0.2cm}
\paragraph{Other points / questions raised:}
\begin{itemize}
	\item {\color{red}R2} The work on composite proper losses from Williamson and collaborators is focused on eliciting the entire label distribution, rather than a property of that distribution as in our setting.  However, in eliciting the entire distribution, we agree the concepts are very similar, and will acknowledge this line of work.
	
	\item {\color{red} R2} and {\color{blue} R3}  That calibration implies indirect elicitation follows immediately from the definition.  To see that indirect elicitation can be strictly weaker, consider hinge loss with the link $\psi(u) = 2 \Ind{u < 1} - 1$.  We have hinge loss indirectly eliciting the mode via this link, as the linked minimizer of the surrogate always maps to the most likely outcome.  However, this link is not calibrated, as the excess risk by target loss misprediction can approach 0 by predicting u arbitrarily close to 1 for any $p$ such that $Pr[Y=1] > 1/2$.  
	
	\item {\color{red}R2} We agree, the concept of indirect elicitation dates back to Lambert et al. (EC 2008) and perhaps before, and connections to consistency were clarified in AA15.  Since our literature review is mixed with the background section, these references were delayed; we will include them earlier.
	
\end{itemize}

      \end{document}