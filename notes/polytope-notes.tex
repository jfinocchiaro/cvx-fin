\documentclass[12pt]{article}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{lmodern}
\usepackage{hyperref}       % hyperlinks  %[implicit=false, bookmarks=false]
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage[margin=1.0in]{geometry}

\usepackage{mathtools, amsmath, amssymb, amsthm, graphicx, verbatim}
%\usepackage[thmmarks, thref, amsthm]{ntheorem}
\usepackage{color}
\definecolor{darkblue}{rgb}{0.0,0.0,0.2}
\hypersetup{colorlinks,breaklinks,
            linkcolor=darkblue,urlcolor=darkblue,
            anchorcolor=darkblue,citecolor=darkblue}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage[colorinlistoftodos,textsize=tiny]{todonotes} % need xargs for below
%\usepackage{accents}
\usepackage{bbm}
\usepackage{xspace}

\usetikzlibrary{calc}
\newcommand{\Comments}{1}
\newcommand{\mynote}[2]{\ifnum\Comments=1\textcolor{#1}{#2}\fi}
\newcommand{\mytodo}[2]{\ifnum\Comments=1%
  \todo[linecolor=#1!80!black,backgroundcolor=#1,bordercolor=#1!80!black]{#2}\fi}
\newcommand{\raf}[1]{\mynote{green}{[RF: #1]}}
\newcommand{\raft}[1]{\mytodo{green!20!white}{RF: #1}}
\newcommand{\jessie}[1]{\mynote{purple}{[JF: #1]}}
\newcommand{\jessiet}[1]{\mytodo{purple!20!white}{JF: #1}}
\newcommand{\bo}[1]{\mynote{blue}{[Bo: #1]}}
\newcommand{\botodo}[1]{\mytodo{blue!20!white}{[Bo: #1]}}
\newcommand{\btw}[1]{\mytodo{orange!20!white}{BTW: #1}}
\ifnum\Comments=1               % fix margins for todonotes
  \setlength{\marginparwidth}{1in}
\fi


\newcommand{\Opt}{\mathrm{Opt}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\posreals}{\reals_{>0}}%{\reals_{++}}
\newcommand{\dom}{\mathrm{dom}}
\newcommand{\epi}{\text{epi}}
\newcommand{\relint}{\mathrm{relint}}
\newcommand{\prop}[1]{\Gamma[#1]}
\newcommand{\eliccts}{\mathrm{elic}_\mathrm{cts}}
\newcommand{\eliccvx}{\mathrm{elic}_\mathrm{cvx}}
\newcommand{\elicpoly}{\mathrm{elic}_\mathrm{pcvx}}
\newcommand{\elicembed}{\mathrm{elic}_\mathrm{embed}}

\newcommand{\cell}{\mathrm{cell}}

\newcommand{\abstain}[1]{\mathrm{abstain}_{#1}}
\newcommand{\mode}{\mathrm{mode}}

\newcommand{\simplex}{\Delta_\Y}

% alphabetical order, by convention
\newcommand{\C}{\mathcal{C}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\F}{\mathcal{F}}
\renewcommand{\H}{\mathcal{H}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\V}{\mathcal{V}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\renewcommand{\P}{\mathcal{P}}

\newcommand{\risk}[1]{\underline{#1}}
\newcommand{\inprod}[2]{\langle #1, #2 \rangle}%\mathrm{int}(#1)}
\newcommand{\inter}[1]{\mathrm{int}(#1)}%\mathrm{int}(#1)}
%\newcommand{\expectedv}[3]{\overline{#1}(#2,#3)}
\newcommand{\expectedv}[3]{\E_{Y\sim{#3}} {#1}(#2,Y)}
\newcommand{\toto}{\rightrightarrows}
\newcommand{\strip}{\mathrm{strip}}
\newcommand{\trim}{\mathrm{trim}}
\newcommand{\fplc}{finite-piecewise-linear and convex\xspace} %xspace for use in text
\newcommand{\conv}{\mathrm{conv}}
\newcommand{\indopp}{\bar{\mathbbm{1}}}
\newcommand{\ones}{\mathbbm{1}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}

\newcommand{\Ind}[1]{\mathbf{1}\{#1\}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\arginf}{arg\,inf}
\DeclareMathOperator*{\sgn}{sgn}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{conjecture}{Conjecture}
\newtheorem{condition}{Condition}
\newtheorem{claim}{Claim}


\title{Polytope notes}
\date{}

\begin{document}
\maketitle

\section{Preliminaries}
\begin{definition}
	A \emph{polyhedra} in $\reals^d$ is defined by the intersection of a finite number of half-spaces.
	A \emph{polytope} is a bounded polyhedra.
\end{definition}

\begin{definition}[Valid inequality]
	Let $S$ be a set in $\reals^d$.
	A \emph{valid inequality} for $S$ is an inequality that holds for all vectors in $S$.
	That is, the pair $(a,\beta)$ is a valid inequality for $S$ if and only if 
	\begin{align*}
	\inprod{a}{x} &\leq \beta \; \; \forall x \in S~.~
	\end{align*}
\end{definition}

\begin{definition}[Face]\label{def:face}
	For any valid inequality of a polytope, the subset of the polytope of vectors which are tight for the inequality is called a \emph{face} of the polytope.
	That is, the set $F$ is a face of the polytope $T$ if and only if 
	\begin{align*}
	F &= \{x \in T : \inprod{a}{x} = \beta \}
	\end{align*}
	for some valid inequality $(a, \beta)$ of $T$.
\end{definition}

\begin{definition}[Supporting function]
	Let $S$ be a nonempty bounded set in $\reals^d$.
	We call the \emph{supporting function} of $S$ the function $H_S:\reals^d \to \reals$ by
	\begin{align*}
	H_S(a) := \sup_{x \in S}\inprod{a}{x}~.~
	\end{align*} 
\end{definition}

\iffalse
\begin{definition}[Maximizers]
  Let $S \subseteq \reals^d$, and $a \in \reals^d$.
  The \emph{set of maximizers} of $a$ over $S$ is defined as
  \begin{align*}
    \mathcal{S}(S;a) &= \{x \in S : \inprod a x = H_S(a)\}
  \end{align*}
\end{definition}

\begin{definition}[Normal cones]
  Let $T$ be a polytope in $\reals^d$.
  For any face $F$ of $T$, we define its \emph{normal cone} $\N(F;T)$ as the set of vectors for which $F$ is the maximizer set over $T$.
  That is,
  \begin{align*}
    \N(F;T) = \left\{a : F = \mathcal{S}(T; a) \right\}~.~
  \end{align*}
\end{definition}

  It is worth noting that normal cones are generally not closed by this definition, but sometimes we may want to think about the closure of the normal cone.
\fi

\begin{definition}[Minkowski sum]
	Let $S_1, S_2, \ldots, S_n$ be sets of vectors.
	We can define their \emph{Minkowski sum} as the set of vectors which can be written as the sum of a vector in each set.
	Namely,
	\begin{align*}
	S_1 \oplus \ldots \oplus S_n &= \{x_1 + \ldots + x_n : x_i \in S_i \; \forall i \}
	\end{align*}
\end{definition}

\begin{theorem}[EPFL Thesis Theorem 3.1.2]\label{thm:unique-face-decomp}
	Let $T_1, \ldots, T_n$ be polytopes in $\reals^d$ and let $F$ be a face of the Minkowski sum $T := T_1 \oplus \ldots \oplus T_n$.
	Then there are faces $F_1, \ldots, F_n$ of $T_1, \ldots, T_n$ respectively such that $F = F_1 \oplus \ldots \oplus F_n$.
	Moreover, this decomposition is unique.
\end{theorem}

\iffalse 
%used in the construction of V
\begin{corollary}[EPFL Cor 3.1.3]\label{cor:face-decomp-normal-cones}
  Let $T = T_1 \oplus \ldots \oplus T_n$ be a Minkowski sum of polytopes in $\reals^d$, let $F$ be a nonempty face of $T$ , and let $F_1, \ldots, F_n$ be its decomposition.
  Then $\N(F;T) = \N(F_1;T_1) \cap \ldots \cap \N(F_n; T_n)$.
\end{corollary}

%used in proving completeness of constructed V
\begin{corollary}[EPFL Cor 3.1.4]
  Let $F_1, \ldots, F_n$ be nonempty faces of the polytopes $T_1, \ldots, T_n$ respectively, then $F_1 \oplus \ldots \oplus F_n$ is a face of $T_1 \oplus \ldots \oplus T_n$ if and only if the intersection of their normal cones is nonempty.
\end{corollary}
\fi

\begin{theorem}[EPFL Th 3.1.6]\label{thm:support-minksum}
  The supporting function of a Minkowski sum is the sum of the supporting functions of its summands.
\end{theorem}

\begin{definition}[Weighted Minkowski sum]
  If $T_1, \ldots, T_n$ are polytopes in $\reals^d$, we can call $T(\vec p)$ their \emph{weighted} Minkowski sum for $\vec p \in \reals^n_+$
  \begin{align*}
    T(\vec p) &:= \oplus_y p_y T_y = p_1 T_1 \oplus \ldots \oplus p_n T_n
  \end{align*}
\end{definition}

  From the thesis:  \emph{``It is easy to see that the normal fan (undefined here, but consequently normal cones) of $p_i T_i$ does not change as long as $p_i$ is positive.  Since the normal fan of a Minkowski sum can be deduced from that of its summands, we can deduce from this that the conbimatorial properties of $\oplus_y p_y T_y$ stay the same as long as all $p_i$ are positive.''}


  \subsection{Notation and new definitions}
  We will use the following notation throughout the rest of this section.
  Suppose we are given a polytope $T_y \in \reals^d$ and set of vectors $V \in \reals^{k \times d}$.
  Call $e^y \in \reals^k$ the vector such that $e^y_i = \max_{x \in T_y}\inprod{v_i}{x}$.  
  For a finite set $\T = \{T_1, , \ldots, T_n\}$, let us denote the \emph{support matrix} $E = (e^y)_{y=1}^n$.
  \begin{definition}
    We say a set of normals $V$ is \emph{complete} with respect to a polytope $T_y$ if $T_y = \{x \in \reals^d: Vx \leq e^y\}$.
  \end{definition}
  Moreover, we say $V$ is complete with respect to the set of polytopes $\T$ if and only if $V$ is complete with respect to each $T_y \in \T$.

  \subsubsection*{Optimality Condition}
  In general, we know that $\vec 0$ in the subgradient of $f(r)$ if and only if $r$ is an optimum of convex $f$ in general dimensions.
  
  For nice\footnote{for reports on the relative interior of the domain, and something else} conditions, we have $\vec 0 \in \oplus_i f_i$ if and only if $\vec 0 \in \oplus_i \partial f_i(r)$.
  This allows us to consider the following optimality condition:
  \begin{definition}\label{def:optimality}[Optimality]
  	For all $r \in \R$ and $y \in \Y$, we have $r \in \gamma_r \iff \vec 0 \in \oplus_y p_y T_y(r)$.
  \end{definition}
  The polytope $T_y(r)$ can be thought of as $\partial L_y(\varphi(r))$.

  \section{From polytopes to cells}\label{sec:start-polytope}
  In this section, we will suppose we start with a finite set of $n$ polytopes $\T := \{T_1, \ldots, T_n\}$, and we will call $T := T_1 \oplus \ldots \oplus T_n \in \reals^d$ their Minkowski sum.
  We know that every polytope has both a halfspace and vertex representation ($\H$-representation and $\V$-representation, respectively.)
  By existence of the $\H$-representation, we know there must be a matrix $V \in \reals^{k \times d}$ and vector $e \in \reals^k$ such that $T = \{x \in \reals^d : Vx \leq e\}$.
  In fact, with a complete set of normals $V$, we know that $e$ can be the support vector of each of the normals.
  However, finding $V$ is not always easy, so we assume that we are given $V$ for now.
  
  \subsection{Given normals $V$}
  Now, for a given polytope $T(p)$, we want to ask when a given $z \in \reals^d$ is in the polytope $T(p)$.
  We will later generalize to finding the set of $p \in \simplex$ for which $\vec 0 \in T(p)$ by substituting $z= \vec 0$.
  Throughout, assume we have $V$ which is complete for $\T$ and $E$ defined by the support of each normal in $V$ for all $T_y \in \T$.
  We denote $e^y = E_{;y}$ as the $y^{th}$ column of $E$, or equivalently, the support vector for $T_y$ given $V$.
  
  Since we define $T_y = \{x : Vx \leq e^y\}$, we can multiply the right side of the inequality by the constant $p_y \geq  0$ to yield $p_y T_y = \{x : Vx \leq p_y e^y\}$.
  Taking the Minkowski sum of polytopes described by the same set of normals, we can take 
  \begin{align*}
  \oplus_y p_y T_y &= \{x : Vx \leq p_1 E_{;1}\} \oplus \ldots \oplus \{x : Vx \leq p_n E_{;n}\} \\
  &= \{x : Vx \leq p_1 E_{;1} + \ldots + p_n E_{;n}\}\\
  &= \{x : Vx \leq E p\}~.~
  \end{align*}
  The first to second line follows from Theorem~\ref{thm:support-minksum} and preservation of inequalities under addition.
  Now, we have $z \in T(p) \iff \inprod{v_i}{z} \leq (Ep)_i$ for all $v_i \in V$.
  
  Observe that we have $\vec 0 \in T(p)$ if and only if $E p \geq 0$ by substitution, which lines up with our optimality condition in Definition~\ref{def:optimality}.  
  
  We assume $p \in \simplex$, so we now describe the cell $D^\T := \{p \in \simplex : Ep \geq \vec 0\}$ as the set of distributions such that $\vec 0 \in T(p)$.
  In cases where $\T$ is obvious from context, we omit the subscript and just write $D$.
  
  Given the complete set of normals $V$ and constructing the support matrix for $V$ and $\T$, $E$, we observe that $E$ is unique up to rescaling.
  However, as discussed earlier, there are always multiple complete sets of normals for $\T$, and so in that sense, $E$ is not unique.
  
  \subsection{Equivalences}
  In the big picture, we want to know two things.
  First, if we are given a cell $C$, how we can construct a finite set of polytopes $\T = \{T_1, \ldots, T_n\}$ such that $\vec 0 \in T(p) \iff p \in C$.
  Second, we want to know the opposite case: starting from $\T$, can we derive the cell $C \subseteq \simplex$ where $\vec 0 \in T(p)$ for all $p \in C$?
  We start with the latter, leaving the former for future work.
  
  We know that if we are given $\T$ and a complete set of normals $V$, we can describe $D = \{p \in \simplex : Ep \geq \vec 0\}$ as in Section~\ref{sec:start-polytope}.
  However, we do not necessarily have $D' := \{p \in A : Ep \geq \vec 0\} \subseteq \simplex$, and this poses some issues given the construction of the cell $C$ only assuming that we are in the affine span of the simplex, but not necessarily in the simplex.
  
  \begin{lemma}\label{lem:describe-D}
    Suppose we are given polytopes $\T = \{T_1, \ldots, T_n\}$ and a set of normals $V$ that is complete for $\T$.
 	Take $E = (e_{i}^y)$ where $e_{i}^y = \max_{x \in T_y} \inprod{v_i}{x}$, and $D^\T = \{p \in \simplex : Ep \geq \vec 0\}$.
 	
 	Then $\{p \in \simplex : \vec 0 \in \oplus_y p_y T_y\} = \{p \in \simplex: Ep \geq \vec 0\}$.\btw{on the whiteboard: ``stuff about $E$ and $D$.''}
  \end{lemma}
  \begin{proof}
    First, let us fix a distribution $p \in \simplex$.
    %We define $T(p) := \oplus_y p_y T_y$ to be the $p$-weighted Minkowski sum over the polytopes in $\T$.
    By Theorem~\ref{thm:support-minksum}, we have the support of the (weighted) Minkowski sum is the (weighted) sum of the support of each polytope, which we can re-write the weighted support as the product $Ep$.
    
    Each halfspace is bounded by the support function of the weighted polytope by construction of $E$, so the support of the weighted polytope defined by an inequality on $v_i$ can be described as $\inprod{v_i}{z} \leq \inprod{E_i}{p}$.
    Taking this for all $v_i$, we then have $\oplus_y p_y T_y = \{x \in \reals^d : Vx \leq Ep\}$.
    	
    Therefore, for fixed $p$, we have $\vec 0 \in \oplus_y p_y T_y \iff Ep \geq \vec 0$.
    As $p \in \simplex$ was arbitrary, we observe the stated set equality.
  \end{proof}
  
  \begin{proposition}\label{prop:relate-E-B}
    Suppose we are given polytopes $\T = \{T_1, \ldots, T_n\}$ and a set of normals $V$ that is complete for $\T$.
    Take $E = (e_{iy})$ where $e_{iy} = \max_{x \in T_y} \inprod{v_i}{x}$, and take $D = \{p \in \simplex : Ep \geq \vec 0\}$ and take the minimal rank $B \in \reals^{k \times n}$ such that we have the given cell $C = \{p \in \simplex : Bp \geq \vec 0\}$.
    
    Then $\{p \in \simplex : \vec 0 \in \oplus_y p_y T_y\} = C$	if and only if $C = D$.
    \btw{whiteboard: ``stuff about $E$ and $B$.''}
  \end{proposition}
  \begin{proof}
  	By Lemma~\ref{lem:describe-D}, we have $D = \{p \in \simplex : \vec 0 \in \oplus_y p_y T_y\}$, and the result follows.
  \end{proof}

  \begin{definition}
  	We say a vector $v$ is \emph{redundant} with respect to matrix $Y$ if we have $\{z: Yz \geq \vec b\} = \{z : [Y;v]z \geq \vec b^*\}$, where $b^* = [b;c]$ for some constant $c \in \reals$.
  \end{definition}

  \begin{proposition}\label{prop:relate-rows}
  	Suppose we have polytopes $\T = \{T_1, \ldots, T_n\}$ and a set of normals $V$ that is complete for $\T$.
  	Take $E = (e_{i}^y)$ where $e_{i}^y = \max_{x \in T_y} \inprod{v_i}{x}$, and take $D = \{p \in \simplex : Ep \geq \vec 0\}$ and take the minimal matrix $B$ such that a given cell $C = \{p \in \simplex : Bp \geq \vec 0\}$.
  	
  	Then $\{p \in \simplex : \vec 0 \in \oplus_y p_y T_y\} = C$	if and only the rows of $B$ appear in $E$ (possibly scaled) and every other row of $E$ is redundant with respect to $B$.
  	\btw{``replace prop 1 statement with `non-simplex rows of $B$ appear in $E$ (possible scaled) and every other row of $E$ is redundant with respect to $B$.'''}
  \end{proposition}
  \begin{proof}
	\begin{itemize}
		\item [$\implies$] First, assume $C = \{p \in \simplex: \vec 0 \in \oplus_y p_y T_y\}$.
		By Proposition~\ref{prop:relate-E-B}, we know that $C = D^\T := \{p \in \simplex : Ep \geq \vec 0\}$.
		Then we have $\{p \in \simplex : Bp \geq \vec 0\} = \{p \in \simplex : Ep \geq \vec 0\}$.
		As $B$ is minimal, we must have that every row of $B$ appears (possibly scaled) in $E$.
		Otherwise, we would contradict equality of the polytopes $C$ and $D$.
		Moreover, all rows in $E$ not in $B$ are redundant with respect to $B$ by equality of the polytopes.
		
		
		\item [$\impliedby$] Suppose that all rows of $B$ appear in $E$, and every other row of $E$ is redundant with respect to $B$.
		Then we have $D = \{p\in \simplex : Ep \geq \vec 0\} = \{p \in \simplex : Bp \geq \vec 0\} = C$.
				
		Then $D = C$, and by Proposition~\ref{prop:relate-E-B}, we have $C = \{p \in \simplex : \vec 0 \in \oplus_y p_y T_y\}$.
	\end{itemize}
  \end{proof}

  \section{Necessary and sufficient conditions for optimality}
  In this section, we have a collection of polytopes $\T = \{T^r_y \subseteq \reals^d : r \in \R, y \in \Y\}$.
  For each fixed $r$, we write $\T^r := \{T^r_y : y \in \Y\}$.
  Given a vector $p \in \reals^n$ (for us, always a probability distribution), we write the $p$-weighted Minkowski sum of $\T^r$ as
    \[ \oplus_p \T^r := \oplus_{y \in \Y} p(y) T^r_y , \]
  where $p(y) T^r_y = \{ p(y) x : x \in T^r_y\}$, i.e. the set $T^r_y$ scaled by $p(y)$, and the Minkowski sum of these $|\Y|$ scaled sets consists of all points $x$ that can be written as a sum of points, one from each set.

  Recall the optimality condition:
  \begin{definition}[Optimality of subgradients for a level set]
    Given a collection of polytopes $\T = \{T_y \subseteq \reals^d : y \in \Y\}$ and a polytope $C \subseteq \Delta_{\Y}$, the \emph{optimality condition $\Opt(\T, C)$ holds} if $p \in C$ if and only if $\vec{0} \in \oplus_p T_y$.
  \end{definition}

  Recall the main characterization theorem:
  \begin{theorem}
    Let $\ell: \R \to \reals_{\geq 0}^{\Y}$ be a discrete loss with, for each $r \in \R$, $\gamma_r = \{p : r \in \argmin_{r'} p \cdot \ell(r)\}$.
    Then $\ell$ is $d$-embeddable if and only if there exist polytopes $\{T^r_y \subseteq \reals^d : r \in \R, y \in \Y\}$ such that both of the following hold:
    \begin{enumerate}
      \item (Optimality) For all $r \in \R$, we have $\Opt(\T^r, \gamma_r)$.
      \item (Monotonicity) (TODO)
    \end{enumerate}
  \end{theorem}

  \subsection{Necessary conditions}
    With the above results, we actually realize that the matrix $B$ captures a necessary condition for optimality.
    As we showed earlier, we derive the support matrix $E$ such that $\vec 0 \in \oplus_y p_y T_y \iff Ep \geq \vec 0$ by substitution, and in Proposition~\ref{prop:relate-rows}, derive necessary and sufficient conditions on the matrix $B$ such that the optimality condition ($\vec 0$ in the weighted Minkowski sum) holds, and these conditions are in relation to the support matrix $E$.
    
    \begin{condition}[$\H$-condition]\label{cond:H-condition}
    	Given polytopes $\T$ and the cell $C = \{p \in \simplex : Bp \geq \vec 0\}$, there exist normals $v_1, \ldots, v_k$ such that $\max_{z \in T_y} \inprod{v_i}{z} = B_{iy}$ for all $i \in [k]$ and $y \in [n]$.
    \end{condition}
  

  \subsection{Sufficient conditions}
    Now in order to think about sufficient conditions for optimality, consider that convex polytopes all have $\V$-representations.
    Therefore, we can equivalently define the cell $C = \{p \in \simplex : Bp \geq \vec 0\} := \conv(\{p^1, \ldots, p^\ell\})$ for a finite set of distributions $p^j \in \simplex$, indexing with $j \in [\ell]$.
    Any distribution $p \in C$ can then be written as a convex combination of $p^j$ making up the convex hull.
%    , so $\vec 0$ being in those Minkowski sums implies that $\vec 0$ is also in the weighted Minkowski sum of any convex combination. \jessiet{Too hand wavy}
    \begin{condition}[$\V$-condition]\label{cond:V-condition}
    	Given $\T$ and $C = \conv(\{p^1, \ldots, p^\ell\})$, there exist $x_{jy} \in T_y$ such that $\oplus_y p^j_y x_{jy} = \vec 0$ for all $j \in [\ell]$.
    \end{condition}

  These two conditions together give us necessary and sufficient conditions for optimality.
  
  \begin{theorem}\label{thm:nasc-optimality-conditions}
  	Consider $B \in \reals^{k \times n}$ minimally describing $C = \{p \in \simplex : Bp \geq \vec 0\} = \conv(\{p^1, \ldots, p^\ell\})$ for a given convex cell $C$.
  	There exists $\T = \{T_1, \ldots, T_n\}$ such that $D^\T = C$ if and only if there exist normals $v_1, \ldots, v_k$, and points $x_{jy}$ such that the Conditions~\ref{cond:H-condition} and~\ref{cond:V-condition} hold.
  \end{theorem}
  \begin{proof}
  	$\implies$
    First, let there exist polytopes $\T$ so that $D^\T = C$.
    
    Suppose $V^*$ is complete for $\T$.
    Take $V = [v_1, \ldots, v_k]^T$ to be the normals corresponding to the nonredundant rows of $E$ with respect to $B$.
    Each entry of the support matrix $E$ is equal to $B$ for these nonredundant normals by Proposition~\ref{prop:relate-rows}.
    Therefore, Condition~\ref{cond:H-condition} is satisfied with the constructed set of normals $V$.    
%    Condition~\ref{cond:H-condition} is satisfied by the existence of a halfspace representation of the polytopes $T_y$, which requires a superset $V^*$ of $V = [v_1, \ldots, v_k]^T$ such that $V^*$ is complete for $\T$ and reduction of redundant rows from the support matrix $E$, which make up $B$.
    
    Moreover, as $\{ p : Ep \geq \vec 0\} \subseteq \{p : Bp \geq \vec 0\}$ (since rows of $E$ are either in $B$ or redundant), we apply Lemma~\ref{lem:describe-D} to observe that there is a witness $x_y \in T_y$ for all $p \in D^\T$ such that $\oplus_y p_y x_y = \vec 0$, as this is a corollary of our optimality condition.
    In particular, this is true for every distribution $p^j \in \{p^1, \ldots, p^\ell\}$, thus Condition~\ref{cond:V-condition} is satisfied.
    
    \bigskip
    $\impliedby$
    
    Consider the set of polytopes $\T$ given so that there are normals $v_i$ and witnesses $x_{jy}$ satisfying Conditions~\ref{cond:H-condition} and~\ref{cond:V-condition}.
    With these polytopes, we want to show that $D^\T = C$.    

    \bigskip
    $D^\T \subseteq C$.
    \bigskip
    
    We have $D^\T = \{p \in \simplex : \vec 0 \in \oplus_y p_y T_y\}$, and $C = \{p \in \simplex : Bp \geq \vec 0\}$.
    Take $p \not \in C$, and therefore $Bp < \vec 0$, and we will show $p \not \in D^\T$.
    For some row $\bar i$ of $B$, we must have $\inprod{B_{\bar i}}{p} = b < 0$.
    
    By Condition~\ref{cond:H-condition}, we can write polytopes as $T_y = \{x : \inprod{v_i}{x} \leq B_{iy} \; \forall i \in [k]\}$, since the $max$ being equal $B_{iy}$ implies an inequality on all $x \in T_y$.
    Moreover, by Theorem~\ref{thm:support-minksum}, we know the support of the weighted Minkowski sum is $Bp$, so the Minkowski sum can be written $\oplus_y p_y T_y = \{x : \inprod{v_i}{x} \leq (Bp)_i \; \forall i \in [k] \}$.
    As $(Bp)_{\bar i} < 0$, we have that $\vec 0$ is not in $T(p)$, so we have $p \not \in D^\T$.
    Thus, we have shown the contrapositive and have $D^\T \subseteq C$.
    
    \bigskip
    $C \subseteq D^\T$.
    \bigskip
    
    Take $p \in C$ so that $Bp \geq \vec 0$.
    Observe that $D^\T$ is a convex polytope, as there is a complete set of normals $V^*$ for $\T$,\jessiet{haven't shown this in this doc, but doesld be easy enough to argue.} and we know that the support matrix $E$ can be constructed so that $D = \{p \in \simplex : Ep \geq \vec 0\}$, which is convex as it is the intersection of a finite number of halfspaces, bounded by simplex constraints, and closed by the weak inequality.
%    it is bounded by simplex constraints, closed by definition, and convex by \jessie{ARGUE}.
    By Condition~\ref{cond:V-condition}, we have that $p^1, \ldots, p^\ell$ are all in $D^\T$, since such witnesses imply $\vec 0$ is in the weighted Minkowski sum.
    Moreover, as $C = \conv(\{p^1, \ldots, p^\ell\})$, we have $C \subseteq D^\T$.
    
  \end{proof}

  \section{Quadratic program}
  Let us generalize our Conditions~\ref{cond:H-condition} and~\ref{cond:V-condition} into a quadratic feasibility program without given polytopes $\T$.
  
  \begin{theorem}[Quadratic Program]
  	Given a cell $C = \{p \in \simplex : Bp \geq \vec 0\} = \conv(\{p^1, \ldots, p^\ell\}) \subseteq \simplex$, we aim to find normals $v_i$ and witnesses $x_{jy}$ such that
  	\begin{align*}
  	\inprod{v_i}{x_{jy}} \leq B_{iy} && \forall i \in [k], j \in [\ell], y \in [n]\\
  	\sum_y p_y^j x_{jy} = 0 && \forall j \in [\ell]\\
  	v_i, x_{jy} \in \reals^d && \forall i \in [k], j \in [\ell], y \in [n]
 	\end{align*}
  \end{theorem}

  \begin{theorem}
  	Suppose we are given a convex polytope $C \subseteq \simplex$.
  	There exist polytopes $\T$ such that $\{p \in \simplex : \vec 0 \in \oplus_y p_y T_y\} = C$ iff there is a feasible solution to the above quadratic program.
  \end{theorem}
  \begin{proof}
  	$\implies$
    First, suppose there were polytopes $\T$ such that $\{p \in \simplex : \vec 0 \in \oplus_y p_y T_y\} = C$.
        
    We know that since each $\{p^1, \ldots, p^\ell\} \in C$, and therefore $\vec 0 \in \oplus_y p_y T_y$ for each $p \in \{p^1, \ldots, p^\ell\}$, there is a set of witnesses $x_{jy}$ yielding that sum of zero, satisfying the second constraint.
    
    To see these witnesses satisfy the first constraint when their inner product is taken with some set of normals, consider each $v_i$ to be the normal of $\oplus_y T_y$ corresponding to the $i^{th}$ row of $B$.
    We know that every row of $B$ appears in the support matrix of the polytopes $E$ by Proposition~\ref{prop:relate-rows}, and therefore, we have $\inprod{v_i}{x_j} \leq B_{iy}$ for all $x_j \in T_y$, thus the first constraint holds.

    \bigskip
    $\impliedby$
    Suppose there was a feasible solution to the quadratic program above.
    We claim that $\T$ such that $T_y = \conv(\{x_{1y}, \ldots, x_{\ell y} \})$ \jessiet{Tried with these polytopes since they guarantee polytopes, but I can't see where $\{x : Vx \leq B_{;y}\}$ guarantees boundedness... also don't see where to use the first statement of the QP in the proof though, since we don't get the normals of the convex hull necessarily being the normals found by the QP.} forms a valid set of polytopes so that $D^\T = C$, and therefore we satisfy our optimality condition by Proposition~\ref{prop:relate-E-B}.
    
    To see $C \subseteq D^\T$, take $\bar p \in C = \conv(\{p^1, \ldots, p^\ell\})$.
    Then there exists $\lambda \in \Delta_{\ell}$ so that $\bar p = \sum_j \lambda_j p^j$, and in turn, $\bar p_y = \sum_j \lambda_j p^j_y$.
    By satisfying the quadratic program, we know that 
    \begin{align*}
    \sum_y p^j_y x_{jy} &= 0 \;\; \forall j \in [\ell]\\
    \sum_j \sum_y p^j_y x_{jy} &= 0\\
    \sum_y \sum_j p^j_y x_{jy} &= 0\\
    \sum_y \sum_j \lambda_j p^j_y x_{jy} &= 0\\
    \sum_y \sum_j \bar p_y x_{jy} &= 0\\
    \sum_y \bar x_y &= 0 
    \end{align*}
    where $\bar x_y := \sum_j \bar p_y x_{jy} \in \conv(\{x_{1y}, \ldots, x_{\ell y}\}) = T_y$ for all $y \in [n]$.
    As $\bar x$ is a witness that $\vec 0 \in \oplus_y \bar p_y T_y$, we have $\bar p \in D^\T$, thus $C\subseteq D^\T$.
%    To see $C \subseteq D^\T$, take some $p \not \in D^\T$.
%    We then have $\vec 0 \not \in \oplus_y p_y T_y$, which in turn implies that, for al\jessiet{this quantifier seems really important, but I'm not confident it's correct.} $j \in [\ell]$, there are no witnesses $\bar x_{jy}$ so that $\sum_y p^j_y \bar x_{jy} = 0$.
%    If $p \in C$, then we contradict our feasibility constraints, so we conclude that we must have $p \not \in C$.
%    Thus, we have $C \subseteq D^\T$.
        
    To see $D^\T \subseteq C$, take some $p \in D^\T$.
    We know that $p \in D^\T \iff \vec 0 \in \oplus_y p_y T_y$.  
    In particular, $\vec 0$ is in the Minkowski sum for all $p^j$, demonstrated by the witnesses $x_{jy}$ for all $y$.
    By construction, each polytope $T_y$ contains $x_{jy}$, and any $p\in C$ is some convex combination of the $p^j$s, so there is a witness that is a convex combination of the $x_{j}$ witnesses for each $y$ so that $\vec 0$ is in the Minkowski sum.
    Such a witness is in the convex hull of the other witnesses, as the new witness can simply be written as a reweighted sum.
    Therefore, we have $D^\T \subseteq C$
    
  \end{proof}

  \begin{corollary}
  	The minimum dimension $d$ such that the QP has a feasible solution is a lower bound on the embedding dimension of loss $\ell$ eliciting $\gamma$. 
  \end{corollary}
  
  
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
