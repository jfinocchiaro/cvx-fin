\documentclass[12pt]{article}
\PassOptionsToPackage{numbers, compress, sort}{natbib}
\usepackage{../neurips-19/neurips_2019}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks  %[implicit=false, bookmarks=false]
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\usepackage{mathtools, amsmath, amssymb, amsthm, graphicx, verbatim}
%\usepackage[thmmarks, thref, amsthm]{ntheorem}
\usepackage{color}
\definecolor{darkblue}{rgb}{0.0,0.0,0.2}
\hypersetup{colorlinks,breaklinks,
            linkcolor=darkblue,urlcolor=darkblue,
            anchorcolor=darkblue,citecolor=darkblue}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage[colorinlistoftodos,textsize=tiny]{todonotes} % need xargs for below
%\usepackage{accents}
\usepackage{bbm}
\usepackage{xspace}

\usetikzlibrary{calc}
\newcommand{\Comments}{1}
\newcommand{\mynote}[2]{\ifnum\Comments=1\textcolor{#1}{#2}\fi}
\newcommand{\mytodo}[2]{\ifnum\Comments=1%
  \todo[linecolor=#1!80!black,backgroundcolor=#1,bordercolor=#1!80!black]{#2}\fi}
\newcommand{\raf}[1]{\mynote{green}{[RF: #1]}}
\newcommand{\raft}[1]{\mytodo{green!20!white}{RF: #1}}
\newcommand{\jessie}[1]{\mynote{purple}{[JF: #1]}}
\newcommand{\jessiet}[1]{\mytodo{purple!20!white}{JF: #1}}
\newcommand{\bo}[1]{\mynote{blue}{[Bo: #1]}}
\newcommand{\botodo}[1]{\mytodo{blue!20!white}{[Bo: #1]}}
\ifnum\Comments=1               % fix margins for todonotes
  \setlength{\marginparwidth}{1in}
\fi


\newcommand{\reals}{\mathbb{R}}
\newcommand{\posreals}{\reals_{>0}}%{\reals_{++}}
\newcommand{\dom}{\mathrm{dom}}
\newcommand{\epi}{\text{epi}}
\newcommand{\prop}[1]{\Gamma[#1]}
\newcommand{\eliccts}{\mathrm{elic}_\mathrm{cts}}
\newcommand{\eliccvx}{\mathrm{elic}_\mathrm{cvx}}
\newcommand{\elicpoly}{\mathrm{elic}_\mathrm{pcvx}}
\newcommand{\elicembed}{\mathrm{elic}_\mathrm{embed}}
\newcommand{\ubar}{\bar{u}}
\newcommand{\cell}{\mathrm{cell}}

\newcommand{\abstain}[1]{\mathrm{abstain}_{#1}}
\newcommand{\mode}{\mathrm{mode}}

\newcommand{\simplex}{\Delta_\Y}

% alphabetical order, by convention
\newcommand{\C}{\mathcal{C}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}

\newcommand{\risk}[1]{\underline{#1}}
\newcommand{\inprod}[2]{\langle #1, #2 \rangle}%\mathrm{int}(#1)}
\newcommand{\inter}[1]{\mathring{#1}}%\mathrm{int}(#1)}
%\newcommand{\expectedv}[3]{\overline{#1}(#2,#3)}
\newcommand{\expectedv}[3]{\E_{Y\sim{#3}} {#1}(#2,Y)}
\newcommand{\toto}{\rightrightarrows}
\newcommand{\strip}{\mathrm{strip}}
\newcommand{\trim}{\mathrm{trim}}
\newcommand{\fplc}{finite-piecewise-linear and convex\xspace} %xspace for use in text
\newcommand{\conv}{\mathrm{conv}}
\newcommand{\indopp}{\bar{\mathbbm{1}}}
\newcommand{\ones}{\mathbbm{1}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}

\newcommand{\Ind}[1]{\mathbf{1}\{#1\}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\arginf}{arg\,inf}
\DeclareMathOperator*{\sgn}{sgn}

\newcommand{\ellzo}{\ell_{\text{0-1}}}
\newcommand{\ellabs}[1]{\ell_{#1}}
\newcommand{\elltopk}{\ell^{\text{top-$k$}}}
\newcommand{\elltop}[1]{\ell^{\text{top-$#1$}}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{conjecture}{Conjecture}


\title{Consistent Polyhedral Surrogates via Embedding}
%\title{Convex Surrogates via Polyhedral Losses}
\author{%
 Jessica Finocchiaro\raf{Jessie?} \\
 \texttt{jessica.finocchiaro@colorado.edu}\\
 CU Boulder
 \And
 Rafael Frongillo\\
 \texttt{raf@colorado.edu}\\
 CU Boulder
 \And
 Bo\\
 \texttt{bwag@colorado.edu}\\
 MSFT
}

\begin{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix


\section{Top-$k$ surrogate}
Throughout this section, consider the surrogate and discrete loss $L^{top-k}(u)_y~=~\left(\frac{1}{k} \sum_{i=1}^k (u + \ones - e_y)_{[i]} - u_y \right)_+$.

First, we want to write $L^{top-k}$ in a linear form with the $\max(\cdot, 0)$ operation.
Then, using this linear form of the expected loss, we are able to evaluate when certain report values are optimal for the expected loss as a function of $p$.

\subsection{Assumptions and notation}
\subsubsection{Assumptions}
Throughout, we make two assumptions for ease of exposition, but both follow without loss of generality for an optimal report.
First, assume that $u$ is ordered, where $u_1 \geq u_2 \geq \ldots \geq u_n$.
This is without loss of generality, as we can simply reorder $p$ if this is not the case.

Second, we will say $u_{k+1} = \ldots = u_{n-1} = u_n = 0$.
This partially follows from the invariance of $L^{top-k}$ in the $\ones$ direction.
Moreover, for $i > k+1$, this $u_i$ can never affect the $\bar{u}$ term that is added, and can only be subtracted in the case that $i = y$.
Thus, we minimize expected loss by pulling $u_{k+2},\ldots, u_n$ up to $u_{k+1}$.
We then set these terms to $0$ to reach our assumption.

\subsubsection{Notation}
Let $\bar{u} = \frac 1 k \sum_{i = 1}^k u_i$ and similarly, $\bar{u}_{-y} = \frac{1}{k-1} \sum_{i=1, i \neq y}^k u_i$ be the averages of the first $k$ elements of $u$ and the average of the first $k$ elements of $u$ besides $y$, respectively.

We use $\odot$ to denote the Hadamard (element-wise) vector product.

\section{Re-writing the loss}

First, observe that we can re-write
\begin{align*} 
L^{top-k}(u)_y&=\left(\frac{1}{k} \sum_{i=1}^k (u + \ones - e_y)_{[i]} - u_y \right)_+\\ 
&=\left(1 - u_y + \frac{1}{k} \sum_{i=1}^k (u - e_y)_{[i]} \right)_+\\
&=\left(1 - u_y + \frac{1}{k} \sum_{i=1}^k (u - \min(u_y, 1)\Ind{y \leq k})_{i} \right)_+\\
\end{align*}

First, we break this into three cases:
\begin{enumerate}
	\item [$y > k$] Here, we observe that $L^{top-k}(u)_y = (1-u_y + \bar{u})_+ > 0$ for all $u$ given our assumptions, so we don't need to worry about the $\max(\cdot,0)$ operation.
	\item [$y \leq k$, $u_y \leq 1$] Here, $\min(u_y,1) = u_y$, so we can rewrite the loss as $L^{top-k}(u)_y = (1 - \frac {k+1}{k} u_y + \bar u)_+$, which always has the inside term nonnegative.
	\item [$y \leq k$, $u_y > 1$] The term inside $\cdot_+$ of $L^{top-k}(u)_y$ is nonnegative and equal to $1 - \frac 1 k - u_y + \ubar$ when $u_y \leq \bar{u}_{-y} + 1$, and $0$ if $u_y \geq \bar{u}_{-y} + 1$.
\end{enumerate}

Therefore, the expected loss can by written as four summations.
We introduce the constants $t < b \leq k$ to mark the boundaries between cases.
We say $t = \argmax_i \{u_i : u_i > \bar u_{-i} +1\}$ and $b = \argmax_i \{u_i : u_i > 1\}$.
We will argue that we can assume $t = 0$ (i.e. there is no $u_i$ such that $u_i > \bar u_{-i} +1$) for a minimizing report, since reassigning such a $u'_i := \bar u_{-i} +1$ results in $L^{top-k}(u')_i = L^{top-k}(u)_i = 0$, but reduces $L^{top-k}(\cdot)_j$ for all $j \neq i$ by decreasing $\ubar$.

We can now write the expected loss as follows:
\begin{align*}
\inprod{p}{L^{top-k}(u)} &= \sum_{y=1}^n p_y L^{top-k}(u)_y \\
&= \sum_{y=1}^t p_y L^{top-k}(u)_y + \sum_{y=t+1}^b p_y L^{top-k}(u)_y + \sum_{y=b+1}^k p_y L^{top-k}(u)_y + \sum_{y=k+1}^n p_y L^{top-k}(u)_y\\
&= 0 + \sum_{y=t+1}^b p_y (1 - \frac 1 k - u_y + \ubar) + \sum_{y=b+1}^k p_y (1 - \frac{k+1} k u_y + \ubar) + \sum_{y=k+1}^n p_y(1-u_y + \ubar)\\
\end{align*}
Moreover, substituting $j=0$, we can simplify further:
\begin{align*}
&= 1 + \ubar - \inprod{p}{u} - \inprod{p \odot \Ind{y \leq i}}{\frac 1 k \ones} - \inprod{p \odot \Ind{i+1 \leq y \leq k}}{ \frac u k}\\
&= 1 + \ubar - \inprod{p \odot \Ind{y \leq i}}{\frac 1 k \ones + u} - \inprod{p \odot \Ind{i+1 \leq y \leq k}}{ \frac {k+1} k u}\\
\end{align*}
When considering the Bayes Risk, we use this final form of the expected loss.

\subsection{Bayes Risk}


\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
