\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{mathtools, amsmath, amsthm, amssymb, graphicx, verbatim}
%\usepackage[thmmarks, thref, amsthm]{ntheorem}
\usepackage{color}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage[colorinlistoftodos,textsize=tiny]{todonotes} % need xargs for below
%\usepackage{accents}
\usepackage{bbm}
\usepackage{xspace}

\newcommand{\Comments}{1}
\newcommand{\mynote}[2]{\ifnum\Comments=1\textcolor{#1}{#2}\fi}
\newcommand{\mytodo}[2]{\ifnum\Comments=1%
  \todo[linecolor=#1!80!black,backgroundcolor=#1,bordercolor=#1!80!black]{#2}\fi}
\newcommand{\raf}[1]{\mynote{green}{[RF: #1]}}
\newcommand{\raft}[1]{\mytodo{green!20!white}{RF: #1}}
\newcommand{\jessie}[1]{\mynote{purple}{[JF: #1]}}
\newcommand{\jessiet}[1]{\mytodo{purple!20!white}{JF: #1}}
\ifnum\Comments=1               % fix margins for todonotes
  \setlength{\marginparwidth}{1in}
\fi


\newcommand{\reals}{\mathbb{R}}
\newcommand{\posreals}{\reals_{>0}}%{\reals_{++}}

\newcommand{\prop}[1]{\mathsf{prop}[#1]}
\newcommand{\eliccvx}{\mathrm{elic}_\mathrm{cvx}}
\newcommand{\elicpoly}{\mathrm{elic}_\mathrm{pcvx}}
\newcommand{\elicembed}{\mathrm{elic}_\mathrm{embed}}

% alphabetical order, by convention
\newcommand{\D}{\mathcal{D}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\I}{\mathcal{I}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}


\newcommand{\inter}[1]{\mathring{#1}}%\mathrm{int}(#1)}
%\newcommand{\expectedv}[3]{\overline{#1}(#2,#3)}
\newcommand{\expectedv}[3]{\E_{Y\sim{#3}} {#1}(#2,Y)}
\newcommand{\toto}{\rightrightarrows}
\newcommand{\trim}{\mathrm{trim}}
\newcommand{\fplc}{finite-piecewise-linear and convex\xspace} %xspace for use in text
\newcommand{\conv}{\mathrm{conv}}
\newcommand{\ones}{\mathbbm{1}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\arginf}{arg\,inf}
\DeclareMathOperator*{\sgn}{sgn}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{conjecture}{Conjecture}


\title{Finite Property Convex Elicitation Notes}
\author{Raf + \ldots}

\begin{document}

\maketitle

\raf{NOTES from call w/ Bo on 8/13/2018:}
\begin{itemize}
\item We would like a very strong link function, which takes any report in the convex domain, and returns the \emph{full set} of optimal reports, of the original finite property, but this is too strong -- consider abstain and the line segment connecting corner and center vs corner, center, and opposite corner.
So we should at least show the weaker link function that takes any report in the convex domain and returns \emph{some} optimal report of the original property.
\item We can probably prove that if $L$ essentially elicits a finite property, then $L$ is polyhedral on the convex hull of the embedded reports.
\end{itemize}

\section{Notation and Definitions}

Let $\Y$ be a finite outcome space, with $n:=|\Y|$, and $\Delta(\Y)$ be the set of probability distributions over $\Y$.
A \emph{property} is a set-valued function $\Gamma: \P \toto \R$, which assigns a subset of the possible reports $\R$ to each probability distribution in a convex set $\P \subseteq \Delta(\Y)$.
(Here $\Gamma: \P \toto \R$ is shorthand for $\Gamma: \P \to 2^\R$, the power set of $\R$.)
We will often consider $\P \subset \reals^n$, meaning we identify each distribution with the corresponding vector of probabilities, for some fixed ordering of the outcomes $\{y_1,\ldots,y_n\} = \Y$.

A propertiy is \emph{elicitable} if it can be expressed as the minimizer of expected loss for some loss function.
When this loss function is convex, we say the property is \emph{convex elicitable}.
\begin{definition}
  \label{def:elicits}
  A loss function $L: \R \times \Y \to \reals$ \emph{elicits} a property $\Gamma$ if for all $p \in \P$,
  \begin{equation}
    \label{eq:elicits}
    \Gamma(p) = \argmin_{r\in\R} \E_{Y \sim p} L(r, Y)~.
  \end{equation}
  In this case, we say $\Gamma$ is \emph{elicitable}.
  We define $\Gamma_L:p\mapsto \argmin_{r\in\R} \E_{Y \sim p} L(r, Y)$ to be the unique property elicited by $L$.
  If $L(\cdot,y)$ is convex for every $y \in \Y$, we say $\Gamma$ is \emph{convex elicitable}.
\end{definition}

In what follows, we will often write $L(r) := (L(r,y_1),\ldots,L(r,y_n)) \in \reals^\Y \equiv \reals^n$, so that $L : \R \to \reals^\Y$.
The elicitation condition in eq.~\eqref{eq:elicits} then becomes, for all $p\in\P\subset \reals^n$,
\begin{equation}
  \label{eq:elicits-vectorized}
  \Gamma(p) = \argmin_{r\in\R} \; p \cdot L(r)~.
\end{equation}

We define the \emph{level set} of a property at report value $r\in\R$ to be the set $\Gamma_r := \{p\in\P : r \in \Gamma(p)\}$.

\begin{definition}
  Let $r,r'\in\R$.
  We say report $r$ is \emph{dominated by $r'$} if $\Gamma_r \subsetneq \Gamma_{r'}$, \emph{equivalent to $r'$} if $\Gamma_r = \Gamma_{r'}$, and \emph{weakly dominated by $r'$} if it is either dominated or equivalent.
  A report is \emph{redundant} if it is dominated by or equivalent to another report.
  A property $\Gamma$ is \emph{non-redundant} if there are no redundant reports.
\end{definition}

\begin{definition}
A property is \emph{finite} if $\R$ is finite.
\jessiet{If $\R$ is finite or $\Y$?  The set of minimizers will be finite, but don't we want $\R$ to be an interval/convex?}\raft{As written.}
\end{definition}

\begin{definition}
  A finite property is \emph{orderable} if there is an ordering $\R = \{r_1,\ldots,r_k\}$ such that the intersection of consecutive level sets forms a hyperplane.
  \raf{Still not sure what the right definition is for non-finite $\R$... and it would be nice to have a more natural version for finite $\R$!}
  \raf{Also, once we figure out what the 2d version is, we should call this $d$-orientable, as in manifolds, so orderable would become $1$-orientable.}
  In other words, for all $i \in \{1,\ldots,k-1\}$ there is some $a_i\in\reals^n$ such that $\Gamma_{r_i}\cap\Gamma_{r_{i+1}} = \{p\in\P : a_i\cdot p = 0\}$.
\end{definition}

\begin{definition}
  A property is \emph{degenerate} if $\Gamma(p) = \emptyset$ for some $p\in\P$, and \emph{non-degenerate} otherwise.
\end{definition}

\begin{definition}
  We will use the following notation:
  $\Gamma' = \Gamma \cap \R'$ is the property $\Gamma' : p \mapsto \Gamma(p)\cap\R'$.
  $L|_{\R'}: \R' \to \reals^\Y$ is the loss $\L|_{\R'} : r' \mapsto L(r')$.
\end{definition}

\begin{lemma}\label{lem:restrict-reports}
  Let $\R'\subseteq\R$ be report spaces, where $L:\R\to\reals^\Y$ elicits $\Gamma$, and $L|_{\R'}$ elicits $\Gamma'$.
  Then for all $r'\in\R'$, we have $\Gamma_{r'} \subseteq \Gamma'_{r'}$.  
\end{lemma}

\begin{lemma}\label{lem:trim}
  Let $L:\R\to\reals^\Y$ elicit a non-degenerate $\Gamma$.
  There is a unique non-degenerate non-redundant property $\Gamma'$, up to relabeling of the reports, such that $\Gamma' = \Gamma\cap\R'$ for some $\R'\subseteq\R$ .
  Moreover, the loss $L|_{\R'}$ elicits $\Gamma'$.
\end{lemma}
\begin{proof}
  Let $\R_1$ be the set of dominated reports of $\Gamma$, and define $\R_2 = \R\setminus\R_1$
  For all $r \in \R_2$, let $[r]$ be the set of equivalent reports to $r$, including $r$ itself.
  Then we let $\R_2' = \{[r] : r\in\R_2\}$ and $\R' = \varphi(\R_2') \subseteq \R$ where $\varphi$ selects an arbitrary representative of each equivalence class.
  \raf{I think I just used the axiom of choice... but for this paper, $\R'$ will be finite, so only a finite number of equivalence classes.}
  Let $\Gamma' = \varphi \circ \Gamma$; clearly $\Gamma'$ is unique up to the choice of relabeling $\varphi$.

  The non-redundancy of $\Gamma'$ follows immediately from our construction: $\Gamma'$ has no dominated reports, and each report is equivalent only to itself.
  For non-degeneracy, note that a property is non-degenerate if and only if its level sets union to all of $\P$ (every distribution is in some level set).
  By our construction, for all $r\in\R$ there is some $r'\in\R'$ such that $\Gamma_{r} \subseteq \Gamma_{r'}$, either because $r'$ dominates $r$ or the two are equivalent and $r' = \varphi([r])$.
  Thus, as $\Gamma$ was non-degenerate, we have $\P = \cup_{r\in\R} \Gamma_r = \cup_{r'\in\R'} \Gamma_{r'}$, giving non-degeneracy of $\Gamma'$.

\raf{TODO: finish proof that $L'$ elicits $\Gamma'$.  $\Gamma' \supseteq \Gamma \cap \R'$ is easy.}
  Finally, let $L' = L|_{\R'}$, that is, $L':\R'\to\reals^\Y$, $L:r'\mapsto L(r')$.
  We have $r' \in \Gamma(p) \implies r' \in \argmin_{r\in\R} p\cdot~L(r)$ $ \argmin_{r\in\R'} p\cdot~L'(r') $
\end{proof}
Note that non-degeneracy is necessary to make Lemma~\ref{lem:trim} interesting, as otherwise $\Gamma' : p \mapsto \emptyset$ would always suffice.


\begin{definition}\label{def:trim}
  We define $\trim(\Gamma)$ to be the unique $\Gamma'$ in Lemma~\ref{lem:trim}, up to relabeling of the reports.
\end{definition}

\begin{definition}
  We say $L:\R'\to\reals^\Y$ \emph{essentially elicits} a property $\Gamma : \P \toto \R$ if there exists some injective embdedding $\varphi:\R\to\R'$ such that for all $p\in\P,r\in\R$ we have $r \in \Gamma(p) \iff \varphi(r) \in \Gamma_L(p)$.
  Such a property is \emph{essentially elicitable} and if $L$ is convex, \emph{essentially convex elicitable}.
\end{definition}
Note that in particular, $L$ essentially elicits $\trim(\Gamma_L)$.

We will most often use this definition as follows.
Given a finite property $\Gamma : \P \toto \{1,\ldots,k\}$, we will seek some convex loss function $L : \reals^d \to \reals^\Y$ and a set of points $\X=\{x_1,\ldots,x_k\} \subset \reals^d$ such that the map $\varphi:i\mapsto x_i$ exhibits the essential elicitability of $\Gamma$.
\raf{WARNING: I think the following is not true actually.  We need the weaker notion of a link function: given some $L$-optimal report in $\reals^d$, give me (at least) one optimal report according to $\Gamma$.}
In particular, using the set-valued link function $\psi:A\mapsto \varphi^{-1}(A\cap\X)$, we will have $\Gamma = \psi \circ \Gamma_L$, so that $\Gamma$ will be indirectly convex elicitable.

\begin{definition}
  Let $\Gamma:\P\toto\R$ and $\Gamma':\P\toto\R'$.
  We write $\Gamma \equiv \Gamma'$ if there is some bijection $\varphi:\R\to\R'$ such that $\Gamma_r = \Gamma'_{\varphi(r)}$ for all $r\in\R$.
\end{definition}
That is, $\Gamma\equiv\Gamma'$ if the two properties are the same up to relabeling the reports.

\begin{lemma}
  Let $L$ be a convex loss function.
  Then $\Gamma_L$ is non-degenerate if and only if $L(\cdot,y)$ is bounded from below for all $y\in\Y$.
  \raf{Not true; take $L(r,y) = e^r$}
\end{lemma}

\begin{definition}
  We say a loss $L:\reals^d \to \reals^\Y$ is \emph{finite-piecewise-linear and convex (polyhedral)} if for all $y\in\Y$, the function $L(\cdot)_y$ is a piecewise-linear function with finitely many pieces, convex, and bounded from below.
\end{definition}

\section{One dimension}

From Lambert 2018, Theorem 3, a finite property has a strictly order-sensitive score if and only if it is orderable...

\begin{lemma}\label{lem:fplc-directional-deriv}
  Let $L:\reals^d \to \reals^\Y$ be polyhedral, and let $r\in\reals$ be a point of differentiability of $L$.
  Let $d^-(r)_y$ and $d^+(r)_y$ denote the left and right derivative, respectively, of $L(\cdot)_y$ at $r$, so that $d^-(r),d^+(r)\in\reals^\Y$.
  Then for any open interval $(a,b)$ containing $r$ where $L$ is differentiable, we have
$d^+(a) = d^-(r) = d^+(r) = d^-(b)$.
\end{lemma}

\begin{lemma}\label{lem:simple-intervals}
  Let $a<a'$ and $b\leq b'$ such that either $a< 0 < b$ or $b' < 0 < a'$.
  Then there exists $\alpha \in (0,1)$ such that $\alpha b + (1-\alpha) a < 0 < \alpha b' + (1-\alpha) a'$.
\end{lemma}
\begin{proof}
  Suppose $a < 0 < b$.
  Let $w = (a + \min(a',0))/2 < 0$ and take $\alpha = w/(w-b) \in (0,1)$.
  Then $\alpha b + (1-\alpha) w = wb/(w-b) - bw/(w-b) = 0$.
  As $a < w < a'$, the result follows:
  \begin{align*}
    & \alpha b + (1-\alpha) a < \alpha b + (1-\alpha) w = 0~,
    \\
    & \alpha b' + (1-\alpha) a' > \alpha b + (1-\alpha) w = 0~.
  \end{align*}
  Similarly, if $b' < 0 < a'$, we take $w = (\max(a,0)+a')/2 > 0$, and same construction holds.
\end{proof}

\begin{proposition}\label{prop:fplc-trim-char}
  Let $L : \reals \to \reals^\Y$ be polyhedral and let $\R$ be the finite set of its nondifferentiable points.
  Then $\trim(\Gamma_L) \equiv \Gamma_L\cap\R'$ where $\underline r$ is the smallest $r\in\R$ such that $d^+(r)_y > 0$ for some $y\in\Y$, $\overline r$ is the largest such that $d^-(r)_y < 0$ for some $y\in\Y$, and $\R' = \R \cap [\underline r, \overline r]$.
\end{proposition}
\begin{proof}
  Since $L$ is polyhedral, for each $y\in\Y$ we can take $\R_y$ to be the finite set of nondifferentiable points of $L(\cdot)_y$, and then $\R = \cup_{y\in\Y} \R_y$.
  As $L$ is bounded from below, we must have $d^-(\min \R)_y \leq 0$ and $d^+(\max \R)_y \geq 0$ for all $y\in\Y$.
  Thus, $\underline r$ and $\overline r$ are well-defined.

  A fact we will use throughout is that $r\in\reals$ is an element of $\Gamma_L(p)$, if and only if,
  \begin{equation}
    \label{eq:1d-optimality}
    0 \in \partial \; p \cdot L(r) = [p \cdot d^-(r), p \cdot d^+(r)]~,
  \end{equation}
  where $\partial$ denotes the subdifferential with respect to $r$.

  First, we argue that reports outside $[\underline r, \overline r]$ are weakly dominated.
  Let $r < \underline r$ and let $r'$ be the smallest value in $[r,\underline r]\cap \R$, i.e.,\ the next largest nondifferentiable point, which exists as $L$ is polyhedral.
  If $r \in \Gamma_L(p)$, then we must have $d^+(r)\cdot p = 0$, as $d^+(r)\cdot p > 0$ would contradict the definition of $\underline r$.
  Then by Lemma~\ref{lem:fplc-directional-deriv}, as $L$ is differentiable on $(r,r')$, we have $0 = d^+(r)\cdot p = d^-(r')\cdot p$.
  Now, if $r' < \underline r$, we again have $d^+(r')\cdot p = 0$, and so on by induction (recall that $\R$ is finite) until we conclude $d^-(\underline r) = 0$, meaning $\underline r \in \Gamma_L(p)$ as well.
  Similarly, all reports $r > \overline r$ are weakly dominated by $\overline r$.

  We next show that all reports at differentiable points of $L$ are weakly dominated.
  We have already consider points outside of $[\underline r, \overline r]$; in that interval, nondifferentiable points satisfy $r' < r < r''$ where $r',r''\in\R$ and $L$ is differentiable on $(r',r'')$.
  If $r\in\Gamma_L(p)$, then from eq.~\eqref{eq:1d-optimality} we have $d^-(r)\cdot p = 0 = d^+(r) \cdot p$, and by Lemma~\ref{lem:fplc-directional-deriv}, we must also have $d^+(r')\cdot p = 0$ and $d^-(r'')\cdot p = 0$, giving $r',r'' \in \Gamma_L(p)$ as well.

  % Finally, we show that for every $r\in \R'$, there exists some $p\in\P$ such that $\Gamma_L(p)\cap\R' = \{r\}$.
  % For $r = \underline r$, let $\underline y$ exhibiting $d^+(\underline r)_{\underline y} > 0$.
  % Note that $d^-(\underline r)_{\underline y} \leq 0$ by definition of $\underline r$ (see the argument above).
  % Thus, letting $p = \delta_{\underline y}$ be the point distribution on $\underline y$, we then have $\underline r \in \Gamma_L(p)$.
  % As $d^-(r)_{\underline y} > 0$ for $r > \underline r$, we must have $\Gamma_L(p)\cap\R' = \{\underline r\}$.
  % \raft{Note: this is the only place in the argument where I needed to intersect with $\R'$.  The reason: losses like the hinge loss can have... }
  % Similarly for $\overline r$ and the outcome $\overline y$.
  % Now take $r \in (\underline r,\overline r) \cap \R$ and let $y$ be the outcome such that $L(\cdot)_y$ is nondifferentiable at $r$; in particular, $d^-(r)_y < d^+(r)_y$.

  Finally, we show that for every $r\in \R'$, there exists some $p\in\P$ such that $\Gamma_L(p) = \{r\}$.
  Let $\underline y$ exhibit $d^+(\underline r)_{\underline y} > 0$, and $\overline y$ exhibit $d^-(\overline r)_{\overline y} < 0$, and note that $d^-(\underline r)_{\underline y} \leq 0$ and $d^+(\overline r)_{\overline y} \geq 0$ by the argument above.
  We observe that if $r > \underline r$, then $0 < d^-(r)_{\underline y} \leq d^+(r)_{\underline y}$ by definition of $\underline r$ (and monotonicity of $d^+,d^-$).
  Similarly, if $r < \overline r$, then $d^-(r)_{\overline y} \leq d^+(r)_{\overline y} < 0$.

  Now for $r = \underline r$, we have $d^-(r)_{\underline y} \leq 0 < d^+(r)_{\underline y}$ and $d^-(r)_{\overline y} \leq d^+(r)_{\overline y} < 0$, and Lemma~\ref{lem:simple-intervals} gives $\alpha \in (0,1)$ such that $p = \alpha \delta_{\underline y} + (1-\alpha) \delta_{\overline y}$ gives $\Gamma_L(p) = \{\underline r\}$.
  Similarly, Lemma~\ref{lem:simple-intervals} gives an $\alpha$ such that $\Gamma_L(p) = \{\overline r\}$, where $p = \alpha \delta_{\overline y} + (1-\alpha) \delta_{\underline y}$.
  Finally, take $r \in \R' \cap (\underline r, \overline r)$ and let $y$ be the outcome such that $L(\cdot)_y$ is nondifferentiable at $r$; in particular, $d^-(r)_y < d^+(r)_y$.
  If $d^-(r)_y < 0 < d^+(r)_y$ we simply take $p = \delta_y$ and are done.
  Otherwise, consider the case $d^-(r)_y < d^+(r)_y \leq 0$, and as $r > \underline r$, recall that $0 < d^-(r)_{\underline y} \leq d^+(r)_{\underline y}$.
  Lemma~\ref{lem:simple-intervals} again gives $\alpha \in (0,1)$ such that $\Gamma_L(p) = \{r\}$ where $p = \alpha \delta_{y} + (1-\alpha) \delta_{\underline y}$.
  In the other case, we choose $p = \alpha \delta_{y} + (1-\alpha) \delta_{\overline y}$, with $\alpha$ again given by Lemma~\ref{lem:simple-intervals}.
  
  Putting everything together, we see that no report in $\R'$ is weakly dominated, and every report in $\reals\setminus\R'$ is weakly dominated by some report in $\R'$.
  We conclude that $\trim(\Gamma_L) \equiv \Gamma_L \cap \R'$.
\end{proof}

\begin{corollary}\label{cor:fplc-orderable}
  Every polyhedral $L : \reals \to \reals^\Y$ essentially elicits a finite orderable property.
\end{corollary}
\begin{proof}
  From Proposition~\ref{prop:fplc-trim-char}, it suffices to show that $\Gamma_L\cap\R'$ is orderable.
  \raf{I need to reference some other stuff above about $\trim(\Gamma_L)$.}
  Let $\R' = \{r_1,\ldots,r_m\}$ with $r_1 < \cdots < r_m$.
  Recalling the optimality condition for $r_i \in \Gamma_L(p)$ in eq.~\eqref{eq:1d-optimality}, we see that
  \begin{equation*}\label{eq:fplc-level-set}
    \Gamma_{r_i} = \{ p \in \Delta_\Y : p\cdot d^-(r_i) \leq 0 \leq p\cdot d^+(r_{i}) \}~.
  \end{equation*}
  Thus, observing that $d^+(r_i) = d^-(r_{i+1})$ from Lemma~\ref{lem:fplc-directional-deriv}, for all $i$ the intersection $\Gamma_{r_i} \cap \Gamma_{r_{i+1}} = \{ p \in \Delta_\Y : p\cdot d^+(r_i) = 0\}$ is a hyperplane.
\end{proof}


\begin{theorem}\label{thm:fplc-orderable}
  A finite property is essentially convex elicitable in $1$ dimension if and only if it is orderable.
  Moreover, this remains true when restricting to piecewise linear loss functions.
\end{theorem}
\begin{proof}
  From Corollary~\ref{cor:fplc-orderable}, it remains to show two things: (i) \raf{general convex losses}, and (ii) a finite ordeable property is elicitable by a polyhedral loss function.  
\end{proof}

\subsection{New stuff (as of 1/23/2019)}

\begin{definition}
  A property $\Gamma:\Delta_\Y\to\R$ is \emph{monotone} if there are maps $a:\R\to\reals^\Y$, $b:\R\to\reals^\Y$ and a total ordering $<$ of $\R$ such that the following two conditions hold.
  \begin{enumerate}
  \item For all $r\in\R$, we have $\Gamma_r = \{p\in\Delta_\Y : a(r) \cdot p \leq 0 \leq b(r) \cdot p\}$.
  \item For all $r < r'$, we have $b(r) \leq a(r')$ (component-wise).
  % \item For all $r,r'\in\R$ and $p\in\Gamma_{r'}\setminus\Gamma_r$, we have $b(r) \cdot p < 0 \implies r' > r$ and $a(r) \cdot p > 0 \implies r' < r$.
  \end{enumerate}
\end{definition}

\begin{proposition}
  A property $\Gamma:\Delta_\Y\toto\reals$ is elicitable by a convex loss $L : \reals \to \reals^\Y$ if and only if it is monotone.
\end{proposition}
\begin{proof}
  Given such an $L$ eliciting $\Gamma$, we let $a,b$ be defined by $a(r)_y = \partial_- L(r)_y$ and $b(r) = \partial_+ L(r)_y$, that is, the left and right derivatives of $L(\cdot)_y$ at $r$.
  Then $\partial L(r)_y = [a(r)_y,b(r)_y]$.
  We now have $r \in \prop{L}(p) \iff 0 \in \partial p\cdot L(r) \iff a(r)\cdot p \leq 0 \leq b(r) \cdot p$, showing the first condition.
  The second condition follows as the subgradients of $L$ are monotone functions.

  Now given a monotone $\Gamma$, let $L(r)_y = \int_{-\infty}^r b(r')_y dr'$... \raf{FILL IN LATER if we care; only really need the above direction}  
\end{proof}

\begin{lemma}
  If $\gamma$ is monotone, finite, elicitable, and non-redundant, it is orderable.
\end{lemma}

\begin{theorem}
  Let $\gamma$ be a finite elicitable non-redundant property.
  If $\gamma$ is indirectly elicitable via a convex $L:\reals\to\reals^\Y$, then $\gamma$ is 1-embeddable.
  In other words, if $\eliccvx(\gamma)=1$, then $\elicpoly(\gamma) = \elicembed(\gamma)=1$.
\end{theorem}

\section{General dimensions}

\begin{lemma}\label{lem:sum-fplc}
  The sum of polyhedral functions $f_1,\ldots,f_k$ is itself polyhedral.
\end{lemma}
\begin{proof}
  Math.
\end{proof}

\begin{definition}
  Let $f:\reals^d\to\reals$ be polyhedral.
  A \emph{vertex} of $f$ is a vertex of the corresponding convex polytope.
\end{definition}

\begin{lemma}\label{lem:vertiex-subgrad}
  Let $f:\reals^d\to\reals$ be polyhedral.
  For every non-vertex $x$ of $f$, there is a vertex $v$ such that $\partial f(x) \subseteq \partial f(v)$.
\end{lemma}
\begin{proof}
  \raf{I'm thinking of a proof in two parts.  1. lemma from convex polytopes saying that you can always get to a vertex while staying within the current face; 2. all points in a face but no other face (so the relative interior) share the same subgradient set, and at the relative boundary, a superset of that set.}
\end{proof}

\begin{proposition}\label{cor:fplc-finite}
  Every polyhedral $L : \reals^d \to \reals^\Y$ essentially elicits a finite property.
\end{proposition}
\begin{proof}
  Let $f(r) = \sum_{y\in\Y} L(r)_y$ which is polyhedral by Lemma~\ref{lem:sum-fplc}.
  \raf{Perhaps its worth getting into power diagrams here...}
  Let $\R$ be the vertices of the cell complex given by $f$, that is, the points at which $\dim\partial f(r) = d$.
  As $f$ is polyhedral, $\R$ is finite.
  We claim that $L$ essentially elicits $\Gamma_L\cap\R$.
  
  \raf{Now we just need to show that every point *not* on a vertex is weakly dominated by a vertex.}
\end{proof}

\raf{If true, this will be helpful in figuring out what the constraints are in the simplex between neighbering reports!}

Note that the definition of $\R'$ is a generalization of its definition as $[\underline r, \overline r]$ in Proposition~\ref{prop:fplc-trim-char}.
\begin{conjecture}
  Let $L:\reals^d \to\reals^\Y$ be polyhedral, and $\R$ the vertices of $\sum_{y\in\Y} L(\cdot)_y$.
  Then $\trim(\Gamma_L) \equiv \Gamma_L\cap \R'$ where $\R' = \conv \{ \argmin_{r\in\reals^d} L(r)_y : y\in\Y\} \cap \R$.
\end{conjecture}

\begin{conjecture}
  Let $L:\reals^d \to\reals^\Y$ be polyhedral, and $\R$ the vertices of $f(\cdot) = \sum_{y\in\Y} L(\cdot)_y$.
  Then for all $p\in\inter\Delta(\Y)$, the convex hull of $\Gamma_L(p)\cap\R$ is a face of the polytope corresponding to $f$.
\end{conjecture}
\begin{proof}
  \raf{Sketch:}
  The polytope of $f$ is the same as that of $p\cdot L(\cdot)$, since $p$ has full support.  As $p\cdot L$ must be flat between all of $\Gamma_L(p)$, those vertices are on the same face.  Moreover, all vertices on the minimal face containing $\Gamma_L(p)$ are optimal.
\end{proof}


\section{Duality}

\begin{theorem}
  Every elicitable property is essentially elicited by a $|\Y|$-dimensional convex loss function (i.e.,\ is $|\Y|$-embeddable).
\end{theorem}
\begin{proof}
  To work exclusively with convex functions, we will consider a score for $\Gamma$ and then a convex loss.
  Let $\Gamma:\Delta(\Y)\toto\R$ be the given elicitable property, with $\R$ arbitrary, elicited by $S:\R\times\Y\to\reals$.
  Let $G : \Delta(\Y) \to \reals$ be the convex expected score function given by $G(p) = \max_{r\in\R} \E_p S(r,Y)$.
  Let $C : \reals^\Y \to \reals \cup \{\infty\}$ be the convex conjugate of $G$, so $C = G^*$.
  By \raf{results with Ian} we know that for some $\D \subseteq \partial G(\Delta(\Y)) \subseteq \reals^\Y$ we have some bijection $\varphi : \R \to \D$ such that $\Gamma(p) = \varphi^{-1}(\D \cap \partial G(p))$.
  \raft{In other words, $\Gamma$ is a relabeling of subgradients of $G$}
  Thus, we can write
  \begin{equation}
    \label{eq:1}
    r \in \Gamma(p) \iff \varphi(r) \in \partial G(p) \iff p \in \partial C(\varphi(r))~,
  \end{equation}
  where the final equivalence follows from convex duality.
  \raft{Of course, we need to be careful here; this only holds if $G$ is proper and lower semi-continuous, but those should both hold for us.}

  Now define $L(\hat r,y) = C(\hat r) - \hat r \cdot \ones_y$ on the report space $\hat \R = \conv(\D)$;
  we will show that $L$ essentially elicits $\Gamma$.
  As $L$ is convex, we may write the optimality condition as
  \begin{equation}
    \label{eq:2}
    \hat r \in \Gamma_L(p) \iff \hat r \in \argmax_{\hat r'} \E_pL(\hat r',Y) \iff 0 \in \partial \E_pL(\hat r,Y)~,
  \end{equation}
  where of course the subgradient $\partial$ is with respect to $\hat r$.
  Plugging in our definition of $L$, we have
  \begin{align*}
    0 \in \partial \E_pL(\hat r,Y)
    & \iff 0 \in \partial \E_p \left(C(\hat r) - \hat r \cdot \ones_Y\right)
    \\
    & \iff 0 \in \partial \left(C(\hat r) - \hat r \cdot p\right)
    \\
    & \iff 0 \in \partial C(\hat r) - \{p\}
    \\
    & \iff p \in \partial C(\hat r)~.
  \end{align*}
  Putting this together with eq.~\eqref{eq:1}, we have for any $\hat r \in \D$ that
  \begin{equation}
    \label{eq:3}
    \hat r \in \Gamma_L(p) \iff p \in \partial C(\hat r) \iff \varphi^{-1}(\hat r) \in \Gamma(p)~,
  \end{equation}
  which implies that $L$ essentially elicits $\Gamma$ for this $\varphi$.
  (The trivially induced map $\varphi:\R\to\hat\R$ is injective as $\varphi:\R\to\D$ was a bijection.)
  \raf{If we assume $\Gamma$ is non-redundant, I believe we also have $\Gamma = \trim(\Gamma_L)$ using $\D$ is the report set.}
\end{proof}

\section{Full Characterization}

\raf{I'm going to give a sequence of equivalent conditions that get farther and farther from the trivial one.
All propositions for now, but eventually we should just take the last statement, chain the proofs, and call it a theorem.}

\raf{NOTE: I'm a bit fuzzy on the terminology surrounding ``embedding'' that we settled on.  Hopefully what I mean is clear enough!}

We begin with a fairly trivial restatement of the definition of embeddability.
\begin{proposition}
  A finite property $\Gamma:\R\toto\P$ is $d$-embeddable if and only if there exists an embedding $\varphi: \R \to \reals^d$ and polytopes $T(r,y) \subseteq \reals^d$ for all $r\in\R, y\in\Y$, such that the following two conditions hold:
  \begin{enumerate}
  \item For all $r\in\R, p\in\P$, we have $r\in \Gamma(p) \iff 0 \in \sum_{y\in\Y} p_y T(r,y)$, where summation is the Minkowski sum.
  \item For all $y\in\Y$ there exists some convex function $L_y$ such that for all $r\in\R$ we have $T(r,y) = \partial L_y(\varphi(r))$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  If $\Gamma$ is $d$-embeddable, we have a convex loss $L$ such that
  \begin{align*}
    r \in \Gamma(p) &\iff \varphi(r) \in \argmin_{r'\in\reals^d} \E_p L(r',Y)\\
                    &\iff 0 \in \partial \E_p L(\varphi(r),Y) \\
                    &\iff 0 \in \sum_y p_y \partial L(\varphi(r),y)~.
  \end{align*}
  Thus, taking $T(r,y) = \partial L(r,y)$ satisfies (1) and trivially (2) with $L_y = L(\cdot,y)$.
  For the converse, we simply take $L(r,y) = L_y(r)$; by condition (1) and the argument above we have exactly that $L$ essentially elicits $\Gamma$.
  \raf{I just realized: we need to justify why we can assume $L$ has polytopical subgradients, vs just polyhedral.  I think this is equivalent to $L$ being finite on all of $\reals^d$, which we can assume, but will probably need machinery from the first part.}
\end{proof}

To further break down conditions (1) and (2), let us state some known results.
First, some notation: let $H_T(v) = \argmax_{x\in T} v\cdot x$ be the support function, \raf{...}
\begin{proposition}
  \raf{I need an assumption here which I don't fully understand, about the presence of facets in at least one polytope.  Basically, if each polytope was lower-dimensional, this doesn't work because they would still have a nonempty Minkowski sum but there wouldn't be any $(d-1)$-faces.  Not sure how to resolve.}
  Let $T_1,\ldots,T_k\subseteq\reals^d$ be polytopes, and $p\in\Delta_k$ be weights.
  Let  $\mathcal{V}$ be the collection of unit normal vectors to all $(d-1)$-faces in $T_1,\ldots,T_k$.
  Then $x \in \sum_{i=1}^k p_i T_i$ if and only if for all nonzero $v\in\mathcal{V}$, we have $v\cdot x \leq \sum_{i=1}^k p_i H_{T_i}(v)$. 
\end{proposition}
\begin{proof}
  \raf{All refs are to the thesis we used (by Weibel).}

  Let $T := \sum_{i=1}^k p_i T_i$.
  By Theorem 3.1.2, every face $F$ of $T$ can be uniquely written as $F = \sum_{i=1}^k p_i F_i$ where $F_i$ is a face of $T_i$.
  By Corollary 3.1.4, $F = \sum_{i=1}^k p_i F_i$ is a face of $T$ if and only if there exists some unit vector $v\in\reals^d$ which is normal to $p_iF_i$ (and thus $F_i$) for all $i$.
  Focusing on the facets
  
\end{proof}



\newpage\newpage

\section{Jessie's notes}
\raf{... have got it growing oats?}

\jessie{Notes partially for myself, but also with some questions I'm not sure of.  Feel free to correct}

We want some (invertible) representation $\phi: \reals^2 \to \reals$ so that $\forall p \in \P$, $\Gamma(p) = \phi([ x_1, x_2 ])$.

We want $\Gamma(p) = \phi(x) = \argmin_r \E_p L(r, Y)$

\subsection{Geometric median}
Consider $\Gamma(p) = \argmin E_p ||r - Y ||_2$
Let $\phi(x)$ be the representation of $\Gamma(p)$ in $\reals^n$.
Can we represent $\phi$ in some lower dimensional manner so that $\phi(x) = \Gamma(p)$ for all $p \in \P$?

The level sets of the geometric median intersect (see the git repo) so it's not elicitable.

Can we/do we want to construct a voronoi diagram of the geometric median?

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
