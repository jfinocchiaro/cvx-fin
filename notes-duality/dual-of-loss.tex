\documentclass[12pt]{article}
\usepackage{amsmath,amsthm,amsfonts,amssymb}

\DeclareMathOperator*{\argmin}{\textrm{argmin}}

\begin{document}

For each outcome $\omega$, we have a loss function $\ell(\cdot, \omega)$.

Let's say it's piecewise linear, then we can write it as
  \[ \ell(\theta, \omega) = \max_{z \in Z} \theta \cdot z - h(z) \]
for a collection of pairs $(z, h(z))$ where $z$ is a slope (or gradient) and $h(z)$ is the negative of a y-intercept.

So this is already basically written in duality form.
The affine function $\theta \mapsto \theta \cdot z - h(z)$ has a convex conjugate which is just the point $(z, h(z))$ with the function equalling infinity elsewhere.
If $\ell$ is the maximum over a finite collection of affine functions, then we just put this finite set of points $\{(z,h(z)) : z \in Z\}$ down, then draw the convex hull to get the function.
(Picture coming later.)

\paragraph{Expected score.}
Now we can define $\ell(\theta ; p) = p \cdot \ell(\theta, \cdot) = \mathbb{E}_{\omega \sim p} \ell(\theta, \omega)$.

Unfortunately it's not apparently simple to relate the convex conjugate of $\ell(\theta; p)$ to the conjugates of $\ell(\theta, \omega)$.

But we have some facts observed by Raf, namely that in the primal space, the polyhedral points stay in the same place.
That means that in the dual space, the set of \emph{slopes} doesn't change.
A ``polyhedral point'' $\theta$ in the primal space corresponds to a slope $\theta$ in the dual space and it lies about the set of $z$ that are gradients above $\theta$ in the primal space.

The slope $\theta$ that crosses the origin in the dual space means that $\theta$ is the optimal report for this belief.

Pictures/example coming later!


\break

\section{Added by Bo 2019-01-11}

\subsection{Convex loss functions and duality}
For each outcome $j=1,\dots,k$, let $\ell_j(x)$ be the loss function.

\paragraph{Scaling}
Given positive $p_j$, note that $(p_j \ell_j)^*$ is the following object:
\begin{enumerate}
  \item Let $F_j^*$ be the epigraph of $\ell_j^*$, a convex set.
  \item Scale the set $F_j^*$ by $p_j$.
  \item This is the epigraph of $(p_j \ell_j)^*$.
\end{enumerate}

\paragraph{Summing}
Given convex $f,g$, note that $(f+g)^*$ is the following object:
\begin{enumerate}
  \item Take the epigraphs $F^*,G^*$ of the functions $f^*,g^*$.
  \item Form the Minkowski sum $F^* + G^*$.
  \item This is the epigraph of $(f+g)^*$.
\end{enumerate}

\paragraph{Convex combination.}
Let $\ell(x;p) = \sum_{j=1}^k p_j \ell_j(x)$.
By the above, we know that (taking the conjugate with respect to the $x$ argument only) $\ell^*(x^*;p)$ is the following object:
\begin{enumerate}
  \item Let $F_j^*$ be the epigraph of $\ell_j^*$.
  \item Form the Minkowski combination $F^*(p) := \sum_{j=1}^k p_j F_j^*$.
  \item This is the epigraph of $\ell^*(x^*;p)$.
\end{enumerate}
The combinatorial properties of $F^*(p)$ don't depend on $p$, as long as each $p_j$ is strictly positive!



\subsection{Optimal reports}
Now $x \in \argmin_x \ell(x;p)$ if and only if $0 \in \partial \ell(x;p)$ if and only if $x \in \partial \ell^*(0 ; p)$.

Fixing $x$

\end{document}
