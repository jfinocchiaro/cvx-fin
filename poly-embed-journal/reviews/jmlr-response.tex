\documentclass[a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{xcolor}
\usepackage{hyperref}

% WHERE HAS THIS BEEN ALL MY LIFE
\usepackage{xr}
\externaldocument{../poly-embed-journal}

\usepackage[colorinlistoftodos,textsize=tiny]{todonotes} % need xargs for below

\newcommand{\Comments}{1}
\definecolor{gray}{gray}{0.5}
\definecolor{lightred}{rgb}{1,0.6,0.6}
\definecolor{darkgreen}{rgb}{0,0.5,0}
\newcommand{\mynote}[2]{\ifnum\Comments=1\textcolor{#1}{#2}\fi}
\newcommand{\mytodo}[2]{\ifnum\Comments=1\todo[linecolor=#1!80!black,backgroundcolor=#1,bordercolor=#1!80!black]{#2}\fi}
\newcommand{\jessie}[1]{\mynote{blue}{[JF: #1]}}
\newcommand{\jessiet}[1]{\mytodo{blue!20!white}{JF: #1}}
\newcommand{\raf}[1]{\mynote{darkgreen}{[RF: #1]}}
\newcommand{\raft}[1]{\mytodo{green!20!white}{RF: #1}}

%\newcommand{\response}[1]{\textcolor{blue!50!black}{Response: #1}}
\newenvironment{response}{\color{blue!50!black}}{\color{black}}

\begin{document}

\begin{center}
  {\Large Response to Reviews on JMLR-22-0743-1}
  
  (An Embedding Framework for the Design and Analysis of Consistent Polyhedral Surrogates)
\end{center}

\raf{OLD TEXT}
  We thank the editor and reviewers for their feedback.  
  \jessie{Not sure what else to write here?}

\\
\\
Regards,\\
Jessie Finocchiaro, Rafael Frongillo, and Bo Waggoner

\subsection*{Response to Reviewer 1}

We thank the reviewer for their thoughtful review and careful reading of our work. We have incorporated the editing suggestions made, and marked in our revised manuscript where non-typo changes to the text were made. 
To answer the first bullet, the reviewer is correct that the pair is not calibrated; we have clarified this point in a following sentence. 
To answer their final question, each element of $\mathcal{U}$ is a set, so the union $\cup \mathcal{U}$ is a set of real-valued $v \in \mathbb{R}^d$; hence it is not a typo. 


\subsection*{Response to Reviewer 2}

We thank the reviewer for the feedback, further resources, and suggestions for improving the clarity of exposition.
We have addressed them all, as detailed below.

\begin{itemize}
\item \textbf{Related work and discussion:}

 We thank the reviewer for the references and questions about the connections to $\H$-consistency and calibration. We have added a discussion about possible extensions to Section~\ref{sec:conclusion}. \jessie{TODO?}
  
\item \textbf{Questions and comments:}
  \begin{enumerate}
  \item \emph{More explanation on why a weak inequality in the definition of separated link (Definition 15) is more natural in applications such as hinge loss for binary classification.}

    Thank you; we clarified the footnote: ``For example, taking hinge loss for binary classification, the sign link is 1-separated under the weak inequality, but only $(1-\delta)$-separated for $\delta > 0$ under the strict inequality.''
    
  \item \emph{Excess error (regret) bounds vs consistency.}

    From our understanding, consistency will always give rise to an excess error bound, e.g.\ by taking the calibration function which looks at the worst-case relationship between the errors.
    Thus what is special about polyhedral losses is the linearity of this bound; indeed, Frongillo and Waggoner (2021) show that ``smooth enough'' surrogate losses always yield a quadratically worse bound.
    
  \item \emph{Optimization of polyhedral losses.}

    We added a footnote to the ``Polyhedral vs.\ smooth'' paragraph in the discussion to make the reviewer's excellent point.
    In general, we lack frameworks which can combine optimization tradeoffs with statistical tradeoffs, making it hard to say whether and when smooth vs polyhedral losses will lead to better computational or statistical performance.
    These questions appear challenging and heavily dependent on the setting (e.g.\ how costly data acquisition vs computation is).
    
  \item \emph{The example in section 5.4 and non-smoothness of polyhedral losses.}

    We are not sure what the reviewer means by ``a Weston--Watkins polyhedral loss'', since we had thought of the Weston--Watkins hinge as a specific surrogate.
    But taking the question to mean ``is there a polyhedral surrogate consistent for 0--1 loss in multiclass settings?'', we added a brief discussion at the end of Section 5.5 (``Surrogates for top-k classification'') giving such a hinge-like surrogate, a special case of the top-$k$ version with $k=1$.
    
  \item \emph{Proposition 21 and upper bounding the original loss.}

    When the target prediction space is finite, one can always (translate and) scale up a consistent convex surrogate until it upper bounds the original loss.
    Thus, while the reviewer may be correct that Bayes risk matching implies that an embedding cannot itself be an upper bound, such as hinge loss embedding \emph{twice} 0--1 loss but not 0--1 loss itself, it can always be corrected to form an upper bound.
    
  \item \emph{Theorem 33 shows that every possible calibrated link must be produced from construction 2. I am wondering if a similar result holds for construction 1 and embedding?} 
  \raf{TODO}

    
  \end{enumerate}

  
\item \textbf{Miscellaneous minor issues and suggestions:}

  We have fixed all minor issues.
  We added the definition of a link function to Definition 6, and emphasized the definition of a calibrated link in Definition 6 as well.
  We added a formal definition of consistency into the appendix with discussion about this definition and its history.\raft{I'm actually wondering if we should just define it in the paper like they suggest... let's see how the appendix section turns out} \jessiet{based on first pass of appendix section, might be in favor of adding in to body.}
  We thank the reviewer for their suggestions to restate Theorems 1 and 2 where relevant; we have done so.

\end{itemize}


\subsection*{Response to Reviewer 3}

We thank the reviewer the feedback. We will discuss the concerns point by point.

\begin{enumerate}
	\item \emph{Is the current framework can be extended to more general class of loss beyond polyhedral?}
	
	The reviewer is correct that the paper is essentially restricted to the polyhedral setting.  (There are extensions beyond the polyhedral case in Section 6, but not far beyond.)  Our goal is not to characterize the full set of consistent surrogates, but to provide a general framework for the design and analysis of polyhedral surrogate losses.
	
	\item \emph{Suggestion for empirical validation on multiclass classification}
	
	We thank the reviewer for the suggestion.  Ultimately, however, we feel that such a toy example would not be very illuminating for our particular results.  For multiclass classification, as in the reviewer’s example, many other papers already cover consistency conditions in theory and practice quite thoroughly, whereas the contribution of our paper is in more complex settings.  Even the comparison among different surrogates for multiclass classification appears in tutorials, blogs, and surveys such as \href{https://faculty.ist.psu.edu/vhonavar/Courses/ds310/lossfunc.pdf}{this}. 
	In lieu of a toy example, we feel that the applications in Section~\ref{sec:applications} illustrate the machinery we develop, leaving the evaluation and demonstration of the resulting surrogates (in the proper contexts) to the follow-up works cited there.
	
	\item \emph{When should we adopt the polyhedral loss instead of existing well-known convex surrogates such as logistic or hinge loss for a particular task?}
	
	To clarify, hinge loss is an example of an embedding.  See the previous response and “Polyhedral vs. smooth surrogates” in Section~\ref{sec:conclusion} for discussion on how to select surrogates.
	
	\item \emph{The claim that ``consistency depends crucially on the choice of link function.''}

	The choice of surrogate loss is of course important for consistency, but so is the choice of link function; see the discussion after Definition~\ref{def:indirect-elic}.  
	(In particular, it seems the reviewer may be fixing the link to be the sign function; e.g. logistic loss is consistent with respect to 0-1 loss when using the sign link, but not with any other link.)	
	
\end{enumerate}



\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
