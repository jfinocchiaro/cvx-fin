@article{zhang2020bayes,
	title={Bayes Consistency vs. H-Consistency: The Interplay between Surrogate Loss Functions and the Scoring Function Class},
	author={Zhang, Mingyuan and Agarwal, Shivani},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	year={2020}
}
,
@article{ramaswamy2016convex,
  title={Convex calibration dimension for multiclass loss matrices},
  author={Ramaswamy, Harish G and Agarwal, Shivani},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={397--441},
  year={2016},
  publisher={JMLR. org}
}
,
@article{ramaswamy2018consistent,
  title={Consistent algorithms for multiclass classification with an abstain option},
  author={Ramaswamy, Harish G and Tewari, Ambuj and Agarwal, Shivani},
  journal={Electronic Journal of Statistics},
  volume={12},
  number={1},
  pages={530--554},
  year={2018},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}
,
@incollection{finocchiaro2018convex,
title = {Convex Elicitation of Continuous Properties},
author = {Finocchiaro, Jessica and Frongillo, Rafael},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {10425--10434},
year = {2018},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8241-convex-elicitation-of-continuous-properties.pdf}
}
,
@article{crammer2001algorithmic,
  title={On the algorithmic implementation of multiclass kernel-based vector machines},
  author={Crammer, Koby and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={2},
  number={Dec},
  pages={265--292},
  year={2001}
}
,
@article{bartlett2008classification,
  title={Classification with a reject option using a hinge loss},
  author={Bartlett, Peter L and Wegkamp, Marten H},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={Aug},
  pages={1823--1840},
  year={2008}
}
,
@incollection{ramaswamy2012classification,
title = {Classification Calibration Dimension for General Multiclass Losses},
author = {Ramaswamy, Harish G and Agarwal, Shivani},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
pages = {2078--2086},
year = {2012},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4528-classification-calibration-dimension-for-general-multiclass-losses.pdf}
}

@article{yuan2010classification,
  title={Classification methods with reject option based on convex risk minimization},
  author={Yuan, Ming and Wegkamp, Marten},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Jan},
  pages={111--130},
  year={2010},
}

@book{grunbaum2013convex,
  title={Convex Polytopes},
  author={Gr{\"u}nbaum, Branko},
  volume={221},
  year={2013},
  publisher={Springer Science \& Business Media},
}
,
@inproceedings{yang2018consistency,
	title={On the consistency of top-k surrogate losses},
	author={Yang, Forest and Koyejo, Sanmi},
	booktitle={International Conference on Machine Learning},
	pages={10727--10735},
	year={2020},
	organization={PMLR}
}
,
@inproceedings{lapin2016loss,
	title={Loss functions for Top-k error: Analysis and insights},
	author={Lapin, Maksim and Hein, Matthias and Schiele, Bernt},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={1468--1477},
	year={2016}
}
,
@article{lapin2018analysis,
	title={Analysis and optimization of loss functions for multiclass, top-k, and multilabel classification},
	author={Lapin, Maksim and Hein, Matthias and Schiele, Bernt},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	volume={40},
	number={7},
	pages={1533--1554},
	year={2018},
	publisher={IEEE}
}
,
@article{yu2018lovasz,
	title={The Lov{\'a}sz Hinge: A Novel Convex Surrogate for Submodular Losses},
	author={Yu, Jiaqian and Blaschko, Matthew B},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	year={2018},
	publisher={IEEE}
}
,
@article{yu2015lovaszarxiv,
  title={The Lov$\backslash$'asz Hinge: A Novel Convex Surrogate for Submodular Losses},
  author={Yu, Jiaqian and Blaschko, Matthew},
  journal={arXiv preprint arXiv:1512.07797},
  year={2015}
}
,
@article{zhang2018reject,
author = {Chong Zhang and Wenbo Wang and Xingye Qiao},
title = {On Reject and Refine Options in Multicategory Classification},
journal = {Journal of the American Statistical Association},
volume = {113},
number = {522},
pages = {730-745},
year  = {2018},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2017.1282372},

URL = { 
        https://doi.org/10.1080/01621459.2017.1282372
    
},
eprint = { 
        https://doi.org/10.1080/01621459.2017.1282372
    
}
}
,
@inproceedings{hazan2010direct,
  title={Direct loss minimization for structured prediction},
  author={Hazan, Tamir and Keshet, Joseph and McAllester, David A},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1594--1602},
  year={2010}
}
,
@inproceedings{gao2011consistency,
  title={On the consistency of multi-label learning},
  author={Gao, Wei and Zhou, Zhi-Hua},
  booktitle={Proceedings of the 24th annual conference on learning theory},
  pages={341--358},
  year={2011}
}
,
@article{duchi2018multiclass,
	title={Multiclass classification, information, divergence and surrogate risk},
	author={Duchi, John and Khosravi, Khashayar and Ruan, Feng},
	journal={The Annals of Statistics},
	volume={46},
	number={6B},
	pages={3246--3275},
	year={2018},
	publisher={Institute of Mathematical Statistics}
}

@inproceedings{osokin2017structured,
	title={On structured prediction theory with calibrated convex surrogate losses},
	author={Osokin, Anton and Bach, Francis and Lacoste-Julien, Simon},
	booktitle={Advances in Neural Information Processing Systems},
	pages={302--313},
	year={2017}
}
,
@inproceedings{pires2013cost,
	title={Cost-sensitive multiclass classification risk bounds},
	author={Pires, Bernardo Avila and Szepesvari, Csaba and Ghavamzadeh, Mohammad},
	booktitle={International Conference on Machine Learning},
	pages={1391--1399},
	year={2013}
}
,
@inproceedings{boser1992training,
	title={A training algorithm for optimal margin classifiers},
	author={Boser, Bernhard E and Guyon, Isabelle M and Vapnik, Vladimir N},
	booktitle={Proceedings of the fifth annual workshop on Computational learning theory},
	pages={144--152},
	year={1992},
	organization={ACM}
}
,
@inproceedings{lapin2015top,
  title={Top-k multiclass SVM},
  author={Lapin, Maksim and Hein, Matthias and Schiele, Bernt},
  booktitle={Advances in Neural Information Processing Systems},
  pages={325--333},
  year={2015}
}

@article{lu2008normal,
  title={Normal fans of polyhedral convex sets},
  author={Lu, Shu and Robinson, Stephen M},
  journal={Set-Valued Analysis},
  volume={16},
  number={2-3},
  pages={281--305},
  year={2008},
  publisher={Springer}
}
,
@book{vapnik1999nature,
	title={The nature of statistical learning theory},
	author={Vapnik, Vladimir},
	year={1999},
	publisher={Springer science \& business media}
}
,
@inproceedings{finocchiaro2019embedding,
	title={An Embedding Framework for Consistent Polyhedral Surrogates},
	author={Finocchiaro, Jessie and Frongillo, Rafael and Waggoner, Bo},
	booktitle={Advances in neural information processing systems},
	year={2019}
}
,
@inproceedings{ramaswamy2015hierarchical,
	title={Convex calibrated surrogates for hierarchical classification},
	author={Ramaswamy, Harish and Tewari, Ambuj and Agarwal, Shivani},
	booktitle={International Conference on Machine Learning},
	pages={1852--1860},
	year={2015}
}
,
@article{finocchiaro2020embedding,
	title={Embedding Dimension of Polyhedral Losses},
	author={Finocchiaro, Jessie and Frongillo, Rafael and Waggoner, Bo},
	journal={The Conference on Learning Theory},
	year={2020}
},

@incollection{menon2019multilabel,
	title = {Multilabel reductions: what is my loss optimising?},
	author = {Menon, Aditya K and Rawat, Ankit Singh and Reddi, Sashank and Kumar, Sanjiv},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {10600--10611},
	year = {2019},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/9245-multilabel-reductions-what-is-my-loss-optimising.pdf}
}
,
@inproceedings{zhang2020convex,
	title={Convex Calibrated Surrogates for the Multi-Label F-Measure},
	author={Zhang, Mingyuan and Ramaswamy, Harish G and Agarwal, Shivani},
	journal={International Conference on Machine Learning},
	year={2020}
}
,
@article{bao2020calibrated,
	title={Calibrated Surrogate Losses for Adversarially Robust Classification},
	author={Bao, Han and Scott, Clayton and Sugiyama, Masashi},
	journal={The Conference on Learning Theory},
	year={2020}
}
,
@article{finocchiaro2021unifying,
	title={Unifying lower bounds on prediction dimension of convex surrogates},
	author={Finocchiaro, Jessie and Frongillo, Rafael and Waggoner, Bo},
	journal={Advances in Neural Information Processing Systems},
	volume={34},
	year={2021}
}
,
@article{wang2020weston,
	title={Weston-Watkins Hinge Loss and Ordered Partitions},
	author={Wang, Yutong and Scott, Clayton},
	journal={Advances in neural information processing systems},
	year={2020}
}
,
@inproceedings{weston1999support,
	title={Support vector machines for multi-class pattern recognition.},
	author={Weston, Jason and Watkins, Chris},
	booktitle={Proceedings of the 7th European Symposium on Artificial Neural Networks},
	year={1999}
}
,
@misc{gallier2008notes,
	title={Notes on Convex Sets, Polytopes, Polyhedra, Combinatorial Topology, Voronoi Diagrams and Delaunay Triangulations}, 
	author={Jean Gallier},
	year={2008},
	eprint={0805.0292},
	archivePrefix={arXiv},
	primaryClass={math.GM}
}
,
@article{zhang2004statistical,
	title={Statistical analysis of some multi-category large margin classification methods},
	author={Zhang, Tong},
	journal={Journal of Machine Learning Research},
	volume={5},
	number={Oct},
	pages={1225--1251},
	year={2004}
}

@article{bach2013learning,
  title={Learning with Submodular Functions: A Convex Optimization Perspective},
  author={Bach, Francis and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={6},
  number={2-3},
  pages={145--373},
  year={2013},
  publisher={Now Publishers, Inc.}
}
,
@INPROCEEDINGS{rastegari2011scalable,
	
	author={Rastegari, Mohammad and Fang, Chen and Torresani, Lorenzo},
	
	booktitle={2011 International Conference on Computer Vision}, 
	
	title={Scalable object-class retrieval with approximate and top-k ranking}, 
	
	year={2011},
	
	volume={},
	
	number={},
	
	pages={2659-2666},
	
	doi={10.1109/ICCV.2011.6126556}}
,
@article{berrada2018smooth,
	author    = {Leonard Berrada and
	Andrew Zisserman and
	M. Pawan Kumar},
	title     = {Smooth Loss Functions for Deep Top-k Classification},
	journal   = {CoRR},
	volume    = {abs/1802.07595},
	year      = {2018},
	url       = {http://arxiv.org/abs/1802.07595},
	eprinttype = {arXiv},
	eprint    = {1802.07595},
	timestamp = {Mon, 13 Aug 2018 16:48:58 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1802-07595.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
,

@InProceedings{williamson2014geometry,
	title = 	 {The Geometry of Losses},
	author = 	 {Williamson, Robert C.},
	booktitle = 	 {Proceedings of The 27th Conference on Learning Theory},
	pages = 	 {1078--1108},
	year = 	 {2014},
	editor = 	 {Balcan, Maria Florina and Feldman, Vitaly and Szepesvári, Csaba},
	volume = 	 {35},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Barcelona, Spain},
	month = 	 {13--15 Jun},
	publisher =    {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v35/williamson14.pdf},
	url = 	 {https://proceedings.mlr.press/v35/williamson14.html},
	abstract = 	 {Loss functions are central to machine learning because they are the means by which the quality of a prediction is evaluated. Any loss that is not proper, or can not be transformed to be proper via a link function is inadmissible. All admissible losses for n-class problems can be obtained in terms of a convex body in \mathbbR^n.  We show this explicitly and show how some existing results simplify when viewed from this perspective.  This  allows the development of a rich algebra of losses induced by binary operations on convex bodies (that return a convex body).  Furthermore it allows us to define an “inverse loss” which provides a universal “substitution function” for the Aggregating Algorithm.  In doing so we show a formal connection between proper losses and norms. }
}
,
@article{dogan2016unified,
	title={A Unified View on Multi-class Support Vector Classification.},
	author={Dogan, {\"U}r{\"u}n and Glasmachers, Tobias and Igel, Christian},
	journal={J. Mach. Learn. Res.},
	volume={17},
	number={45},
	pages={1--32},
	year={2016}
}
,

@InProceedings{liu2007fisher,
	title = 	 {Fisher Consistency of Multicategory Support Vector Machines},
	author = 	 {Liu, Yufeng},
	booktitle = 	 {Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics},
	pages = 	 {291--298},
	year = 	 {2007},
	editor = 	 {Meila, Marina and Shen, Xiaotong},
	volume = 	 {2},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {San Juan, Puerto Rico},
	month = 	 {21--24 Mar},
	publisher =    {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v2/liu07b/liu07b.pdf},
	url = 	 {https://proceedings.mlr.press/v2/liu07b.html},
	abstract = 	 {The Support Vector Machine (SVM) has become one of the most popular machine learning techniques in recent years. The success of the SVM is mostly due to its elegant margin concept and theory in binary classification. Generalization to the multicategory setting, however, is not trivial. There are a number of different multicategory extensions of the SVM in the literature. In this paper, we review several commonly used extensions and Fisher consistency of these extensions. For inconsistent extensions, we propose two approaches to make them Fisher consistent, one is to add bounded constraints and the other is to truncate unbounded hinge losses.}
}

@article{finocchiaro2022consistenttopk,
	title={Consistent Polyhedral Surrogates for Top-$k$ classification and Variants},
	author={Finocchiaro, Jessie and Frongillo, Rafael and Goodwill, Emma and Thilagar, Anish},
	journal={International Conference on Machine Learning},
	year={2022}
}

@article{ourlovaszpaper,
	title={The Structured Abstain Problem and the Lov\'{a}sz Hinge},
	author={Finocchiaro, Jessie and Frongillo, Rafael and Nueve, Enrique},
	journal={Conference on Learning Theory},
	year={2022}
}
,
@article{elyaniv2010foundations,
	author  = {Ran El-Yaniv and Yair Wiener},
	title   = {On the Foundations of Noise-free Selective Classification},
	journal = {Journal of Machine Learning Research},
	year    = {2010},
	volume  = {11},
	number  = {53},
	pages   = {1605-1641},
	url     = {http://jmlr.org/papers/v11/el-yaniv10a.html}
}
,
@article{madras2018predict,
	title={Predict responsibly: improving fairness and accuracy by learning to defer},
	author={Madras, David and Pitassi, Toni and Zemel, Richard},
	journal={Advances in Neural Information Processing Systems},
	volume={31},
	year={2018}
}
,
@inproceedings{cortes2016learning,
	title={Learning with rejection},
	author={Cortes, Corinna and DeSalvo, Giulia and Mohri, Mehryar},
	booktitle={International Conference on Algorithmic Learning Theory},
	pages={67--82},
	year={2016},
	organization={Springer}
}
,
@book{gyorfi2002distribution,
	title={A distribution-free theory of nonparametric regression},
	author={Gy{\"o}rfi, L{\'a}szl{\'o} and Kohler, Michael and Krzy{\.z}ak, Adam and Walk, Harro},
	volume={1},
	year={2002},
	publisher={Springer}
}
,
@article{fan1998efficient,
	title={Efficient estimation of conditional variance functions in stochastic regression},
	author={Fan, Jianqing and Yao, Qiwei},
	journal={Biometrika},
	volume={85},
	number={3},
	pages={645--660},
	year={1998},
	publisher={Oxford University Press}
}

@article{zalinescu2003sharp,
  title={Sharp estimates for Hoffman's constant for systems of linear inequalities and equalities},
  author={Zalinescu, Constantin},
  journal={SIAM Journal on Optimization},
  volume={14},
  number={2},
  pages={517--533},
  year={2003},
  publisher={SIAM}
}

@article{hoffman1952approximate,
  title={On Approximate Solutions of Systems of Linear Inequalities},
  author={Hoffman, Alan J},
  journal={Journal of Research of the National Bureau of Standards},
  volume={49},
  number={4},
  year={1952}
}


@article{frongillo2021surrogate,
  title={Surrogate Regret Bounds for Polyhedral Losses},
  author={Frongillo, Rafael and Waggoner, Bo},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}
,
@inproceedings{reddi2019stochastic,
	title={Stochastic negative mining for learning with large output spaces},
	author={Reddi, Sashank J and Kale, Satyen and Yu, Felix and Holtmann-Rice, Daniel and Chen, Jiecao and Kumar, Sanjiv},
	booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
	pages={1940--1949},
	year={2019},
	organization={PMLR}
}
,
@article{klain2004minkowski,
	title={The Minkowski problem for polytopes},
	author={Klain, Daniel A},
	journal={Advances in Mathematics},
	volume={185},
	number={2},
	pages={270--288},
	year={2004},
	publisher={Elsevier}
}
,
@inproceedings{reid2012convexity,
	title={The convexity and design of composite multiclass losses},
	author={Reid, Mark D and Williamson, Robert C and Sun, Peng},
	booktitle={Proceedings of the 29th International Coference on International Conference on Machine Learning},
	pages={243--250},
	year={2012}
}
,
@inproceedings{asif2015adversarial,
	title={Adversarial Cost-Sensitive Classification.},
	author={Asif, Kaiser and Xing, Wei and Behpour, Sima and Ziebart, Brian D},
	booktitle={Conference on Uncertainty in Artificial Intelligence},
	pages={92--101},
	year={2015}
}
,
@article{fathony2016adversarial,
	title={Adversarial multiclass classification: A risk minimization perspective},
	author={Fathony, Rizal and Liu, Anqi and Asif, Kaiser and Ziebart, Brian},
	journal={Advances in Neural Information Processing Systems},
	volume={29},
	year={2016}
}
,
@article{farnia2016minimax,
	title={A minimax approach to supervised learning},
	author={Farnia, Farzan and Tse, David},
	journal={Advances in Neural Information Processing Systems},
	volume={29},
	year={2016}
}
,
@book{schneider2014convex,
	title={Convex bodies: the Brunn--Minkowski theory},
	author={Schneider, Rolf},
	number={151},
	year={2014},
	publisher={Cambridge university press}
}