\documentclass{article}

\usepackage{neurips_2020_author_response}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{mathtools, amsmath, amsthm, graphicx}
\newcommand{\reals}{\mathbb{R}}

\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}

%\newcommand{\ker}{\mathrm{ker}}


\begin{document}
We thank the reviewers for their thoughtful comments and feedback.  We will reply to common themes followed by individual responses.  The minor technical notes not mentioned will also be addressed in our next revision.  

\textbf{Notation:} We will clarify notation including: $|\Y| = n$ (and that it is always finite in this paper), $\underline{L}$ = Bayes Risk($L$), and $\partial$ is the subdifferential; and set-notation in line 321.

\textbf{Examples:} We agree that earlier examples would be beneficial to help readers build intuition, and thank the reviewers for the suggestions. We plan to use abstain and variance estimation as running examples for different quadrants starting from Section 2.  

\textbf{Motivation of dimension (particularly for continuous predictions):}  The surrogate loss is one small part of the entire learning algorithm, whose complexity is a function of the prediction dimension among other things.  While reducing prediction dimension from $n$ to $n-1$ may not be overwhelmingly beneficial, an exponential reduction, like that observed in the BEP abstain surrogate [22], can significantly improve the efficiency of the learning algorithm as a whole.  As demonstrated in this paper, prediction dimension bounds are often a function of the number of outcomes $n$, which does not bode well for infinite outcome tasks.  This highlights the beauty of variance having a \emph{constant} prediction dimension, though this does not generalize across continuous prediction problems.  Other continuous predictions problems such as upper confidence bounds are not well understood, despite its practical desirability for estimating numerical model reliability in engineering domains.


\textbf{R1:}  We hope the earlier introduction of examples will improve clarity and improve the intuition for notation. $\ker(W)$ is the kernel of the matrix $W$.
For broader impacts, we note that the conference organizers write, ``if your work is very theoretical or is general enough that there is no particular application foreseen, then you are free to write that a Broader Impact discussion is not applicable.’’\footnote{\url{https://neurips.cc/Conferences/2020/PaperInformation/NeurIPS-FAQ}}


\textbf{R2:}  Regarding indirection elicitation, the implication of inclusion is correct, and we will add this for intuition.


\textbf{R3:} We hope the ``motivation of dimension’’ paragraph above helps clarify the significance of finding lower bounds.


\textbf{R5:} Regarding Theorems 2 and 3, it is correct that the best lower bound is the supremum over choices of $r$ and $p$. We agree that could be a good presentation, although stylistically we had reasons for our current approach. These include: this suprema does not seem to have a nice closed form; one’s intuition often leads to the best particular choice of $r$ and $p$; and this presentation matches that of [21, Theorem 16].

The relint(simplex) question is interesting. In every example we’ve seen, the supremum p is in the interior, but we cannot prove this will always be true; it’s an open question.

We agree Theorem 1 is rather straightforward (it is more of an observation than a result, per se).  We felt it important to emphasize given how crucial it is for proving Theorems 2 and 3.

Regarding the citation in line 161, more general proofs have been derived by [28] (multiclass classification) and [21] (general matrix losses), but the proof is given most rigorously by [2].  We will add the other citations. Thanks for the clarification on [28] and its NeurIPS 2012 version.

The notion of feasible subspace dimension comes from [21]; we can add a visual explanation in the Appendix, as well as an explanation for eliciting the first two moments.  In line 287, there was a typo that muddled our intention: we meant ``a line in two-dimensional space’’, i.e. $\reals^2$.

We only speculate that a lower prediction dimension may imply lower sample complexity. Our intuition is that, all else equal, lower prediction dimension allows for an equally-expressive hypothesis class of smaller VC-dimension or Rademacher complexity, which implies a better sample complexity bound. It would be very interesting to formalize, but difficult because of the importance of the rest of the context (original prediction dimension, link function, hypothesis classes, …).  We will clarify this is speculation.
Thank you for other comments and suggestions.

\textbf{R6:}  It is a great point that we need to emphasize approximate minimizers while giving intuition for consistency, and we will clarify.  We will also direct the reader to Chapter 3 of [27] for intuition about the conditional problem.

Translating results from conditional distributions to those on $\X \times \Y$: this is rigorously addressed by [2] and [28], which we can emphasize. It would be interesting to explore conditions under which indirect elicitation is \emph{sufficient} for consistency. Since we assume $\Y$ is finite, we would only need to show indirect elicitation implies calibration, then cite prior work. This seems likely with reasonable restrictions on the link function.

Connection to the definition of calibration in [27]: you are correct. Calibration functions are especially important when considering generalization rates. In contrast, our interest in consistency precedes discussions of rates, which we hope to study in future work.

Technical difficulties with infinite infimum expected loss: We do avoid this problem in this paper by only considering situations where there always exists a minimizer of expected loss. For losses, this follows by definition of $\mathcal{L}$. For properties, it follows from nonemptiness. Understanding other cases is indeed interesting! We will emphasize this assumption throughout.

Thanks for the comments regarding definitions at the beginning of the paper. We feel that we seem to quickly require almost all these definitions to state results, except calibration. However, most ML readers wish to see how calibration relates, so we cannot drop it either.  We will carefully consider organization and these suggestions.

Thanks for all other comments.

\end{document}
