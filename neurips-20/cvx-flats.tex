\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2020

% ready for submission
% \usepackage{neurips_2020}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2020}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2020}

% to avoid loading the natbib package, add option nonatbib:
\usepackage{neurips_2020}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsmath, amsfonts, amssymb, amsthm}

\usepackage{color}
\definecolor{darkblue}{rgb}{0.0,0.0,0.2}
\hypersetup{colorlinks,breaklinks,
	linkcolor=darkblue,urlcolor=darkblue,
	anchorcolor=darkblue,citecolor=darkblue}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage[colorinlistoftodos,textsize=tiny]{todonotes} % need xargs for below
%\usepackage{accents}
\usepackage{bbm}
\usepackage{xspace}

\newcommand{\Comments}{1}
\newcommand{\mynote}[2]{\ifnum\Comments=1\textcolor{#1}{#2}\fi}
\newcommand{\mytodo}[2]{\ifnum\Comments=1%
	\todo[linecolor=#1!80!black,backgroundcolor=#1,bordercolor=#1!80!black]{#2}\fi}
\newcommand{\raf}[1]{\mynote{green}{[RF: #1]}}
\newcommand{\raft}[1]{\mytodo{green!20!white}{RF: #1}}
\newcommand{\jessie}[1]{\mynote{purple}{[JF: #1]}}
\newcommand{\jessiet}[1]{\mytodo{purple!20!white}{JF: #1}}
\newcommand{\proposedadd}[1]{\mynote{orange}{#1}}
\newcommand{\bo}[1]{\mynote{blue}{[Bo: #1]}}
\newcommand{\botodo}[1]{\mytodo{blue!20!white}{[Bo: #1]}}
\newcommand{\btw}[1]{\mytodo{gray!20!white}{[BTW: #1]}}%TURN OFF FOR NOW \mytodo{gray}{#1}}
\ifnum\Comments=1               % fix margins for todonotes
\setlength{\marginparwidth}{1in}
\fi

\newcommand{\reals}{\mathbb{R}}
\newcommand{\posreals}{\reals_{>0}}%{\reals_{++}}
\newcommand{\simplex}{\Delta_\Y}
\newcommand{\prop}[1]{\mathrm{prop}[#1]}
\newcommand{\elic}{\mathrm{elic}}
\newcommand{\eliccvx}{\mathrm{elic}_\mathrm{cvx}}
\newcommand{\elicpoly}{\mathrm{elic}_\mathrm{pcvx}}
\newcommand{\elicembed}{\mathrm{elic}_\mathrm{embed}}
\newcommand{\ccdim}{\mathrm{ccdim}}
\newcommand{\codim}{\mathrm{codim}}

\newcommand{\C}{\mathcal{C}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\N}{\mathcal{N}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\R}{\mathcal{R}}
\renewcommand{\S}{\mathcal{S}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}


\newcommand{\risk}[1]{\underline{#1}}
\newcommand{\inprod}[2]{\langle #1, #2 \rangle}
\newcommand{\toto}{\rightrightarrows}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{conjecture}{Conjecture}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\arginf}{arg\,inf}
\DeclareMathOperator*{\sgn}{sgn}

\title{cvx-flats}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Jessie Finocchiaro\\
%  Department of Computer Science\\
  CU Boulder\\
  \texttt{jefi8453@colorado.edu} 
  % examples of more authors
  \And
   Rafael Frongillo\\
%   Department of Computer Science\\
   CU Boulder\\
  % Address \\
   \texttt{raf@colorado.edu} 
   \And
   Bo Waggoner\\
%   Department of Computer Science\\
   CU Boulder \\
  % Address \\
   \texttt{bwag@colorado.edu} 
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}



\begin{document}

\maketitle

\begin{abstract}
%	For finite prediction tasks, one can often naturally model their specific problem with a discrete loss.
%	However, these discrete losses are often hard to optimize, so one often seeks a surrogate losses yielding desirable statistical guarantees with respect to the original problem.
	In prediction tasks, one typically seeks to minimize \emph{empirical risk} by learning a hypothesis function making predictions from a given feature vector about a desired future outcome.
	This hypothesis is learned by minimizing a loss function over a set of labeled training data.
	However, as not all loss functions are easily optimized, one often wishes to optimize a \emph{surrogate loss} yielding the same statistical guarantees as the original.
	In this paper, we are specifically interested in the construction of \emph{consistent} surrogate losses that are ``efficient'' in the dimension of their input.
	We observe a connection between consistent surrogates and indirect property elicitation, which allows us to apply property elicitation complexity results to the minimal dimension of a consistent surrogate.
	In particular, we characterize the minimal input dimension needed in order to construct a \emph{convex}, consistent surrogate using tools from property elicitation.
\end{abstract}

\section{Introduction}\label{sec:intro}

In supervised machine learning, one often wants to make a prediction about future outcomes by training a classifier to minimize the average empirical loss of a labeled training set, where the loss is determined by the task at hand.
For example, 0-1 loss is often desired for classification tasks.
However, finite losses are typically difficult to optimize, so we construct a continuous \emph{surrogate} loss that one can more easily optimize.
In particular, we want our surrogate loss to yield guarantees so that optimal predictions for the surrogate can be linked to optimal predictions for an original (possibly discrete) loss, regardless of the underlying data distribution.
Moreover, in continuous prediction settings, one often stats with a statistic of the data they would like to estimate, but it is often unclear how to construct a a loss that is consistent for the given property.
For example, if one wants to estimate the $\alpha$-quantile, they can do so by minimizing pinball loss over their data, but it is often unclear \emph{why} pinball loss is good for this prediction task.
Throughout this paper, the statistical guarantees we desire are \emph{consistency}.
In particular, we are specifically interested in consistent \emph{and convex} surrogates in which any optimal prediction can be linked to either the correct prediction for the discrete loss or statistic value, depending on the setting. 

We typically use convex surrogate loss functions that take some input $u \in \reals^d$ and measure error against the observed outcome $y \in \Y$.
The value $d$ provides some notion of efficiency for the surrogate, as low-dimensional convex losses can improve the efficiency of the optimization algorithm.
\cite{frongillo2015elicitation} poses an open question regarding a general characterization of the efficiency of \emph{convex elicitable properties}, which we show is equivalent to finding the minimum dimension $d$ for which a consistent, convex loss can be constructed for the task at hand.

In Section~\ref{sec:related-work}, we review previous work and introduce the two main concepts used: \emph{property elicitation} and \emph{consistency}.
We draw connections between the two in Section~\ref{sec:char-convex}, presenting our main result (Theorem~\ref{thm:cvx-flats},) a corollary of which characterizes the existence of consistent convex surrogates in a given dimension $d$.
In Section~\ref{sec:finite-calib}, we relate our setting to the study of \emph{convex calibration dimension} introduced by~\cite{ramaswamy2016convex} by focusing on the finite prediction setting.
Our Theorem~\ref{thm:cvx-flats} generalizes their \emph{subspace of feasible dimensions}, and we can use our results to generalize and simplify the proof of~\cite[Theorem 16]{ramaswamy2016convex}.
In continuous settings, one often has a prediction task for which they want to construct a consistent convex loss, rather than an original loss.
In Section~\ref{sec:contin-consis}, we address the construction of convex consistent losses by applying the main insights from Theorem~\ref{thm:cvx-flats} to this setting, answering the open question posed by~\cite[Section8]{frongillo2018elicitation}.


\subsection{Notation}
In this paper, we take the outcome set $\Y$ and consider $\simplex$ to be the simplex over $\Y$. 

%discrete land
Let $\R$ be a (sometimes finite) report set and $\Y$ a outcome set; it is not necessary for $\Y = \R$.  
For example, in ranking problems, $\R$ may be all $n!$ permutations over the $n$ outcomes forming $\Y$.
A loss $\ell : \R \times \Y \to \reals_+$ is a \emph{discrete loss} if $|\R| < \infty$, and in general, we use $\ell$ to denote our \emph{original loss} for which we want to construct a consistent surrogate.
We denote $\ell(r)_y$ as the $y^{th}$ element of the vector $\ell(r)$, and consider this to be the punishment for reporting $r$ if outcome $y$ is realized.
For a distribution $p \in \simplex$, we denote the expected discrete loss for report $r$ to be $\E_{Y \sim p} \ell(r, Y) := \ell(r; p)$.
When considering surrogate losses, we denote the loss by $L : \reals^d \times \Y \to \reals_+$, and typically denote a surrogate report with $u$.

Throughout this paper, we use tools from \emph{property elicitation} to understand the existence of consistent surrogate functions.
Introduced in Section~\ref{subsec:properties}, a property $\Gamma: \P \to 2^\R \setminus \emptyset$ is denoted $\Gamma:\P \toto \R$, where $\P \subseteq \simplex$.
We call a property \emph{set-valued} if there is a $p \in \P$ so that $|\Gamma(p)| > 1$, and \emph{single-valued} otherwise.
We use $\Gamma := \prop{L}$ to denote that $\Gamma$ is the (unique) property elicited by $L$.

Throughout this paper, we focus on characteristics of \emph{convex} surrogate losses.
Here, when we say a loss $L(\cdot; p)$ is \emph{convex}, we mean that it is convex in its first argument for every $p \in \P$.
If $\P = \simplex$, this is equivalent to saying $L$ is convex in the report for every outcome $y \in \Y$.

\section{Related work}\label{sec:related-work}
In this paper, we use tools from property elicitation to study the construction of consistent surrogate losses.
We distinguish between finite and infinite outcome settings for prediction tasks.

Property elicitation of a single property is well-understood through \cite{savage1971elicitation,osband1985information-eliciting,lambert2008eliciting, lambert2009eliciting, lambert2018elicitation}.
Recently, the elicitation of multiple properties was studied by~\cite{frongillo2015vector-valued,frongillo2015elicitation,fissler2015higher}.
In particular, these works study the \emph{minimum} dimension of a real-valued loss needed to elicit a property or vector of properties.


\subsection{Property elicitation}\label{subsec:properties}
Informally, a property is a function mapping a probability distribution $p$ over the outcome set $\Y$ to the ``suggested report'' given $p$.

\begin{definition}[Property, elicits, level set]
	A \emph{property} is a (possibly set-valued) function $\Gamma : \simplex \toto \R$ mapping distributions to reports.
	A loss $L : \R \times \Y \to \reals_+$ \emph{elicits} the property $\Gamma$ if,
	\begin{equation}
	\forall p \in \simplex, \;\; \Gamma(p) = \argmin_{r \in \R}\inprod{p}{L(r)}
	\end{equation}
	Moreover, we call a \emph{level set} $\Gamma_r := \{p \in \P : r \in \Gamma(p)\}$ to be the set of distributions for which reporting $u$ minimizes the expected loss of the loss eliciting $\Gamma$.
\end{definition}
Note, moreover, that we call a property $\gamma: \simplex \toto \R$ \emph{finite} if $|\R| < \infty$.
Without much loss of generality, we assume that finite properties are \emph{non-redundant}, meaning that for each $\gamma_r$, there is no $\gamma_{r'}$ such that $\gamma_{r'} \subseteq \gamma_r$.

\cite{finocchiaro2018convex} are among the first to consider a characterization of \emph{convex} elicitable properties, in which they find that all continuous, nowhere locally constant elicitable properties (in finite outcome settings) are elicitable by a \emph{convex} loss.
However, their assumptions are more restrictive than ours; they only consider losses defined on the real line (see Section~\ref{subsec:elic-cplx} below for our generalization) and assume the properties to be identifiable: an assumption we do not need here.
\cite{frongillo2018elicitation} then presents a more general characterization of convex elicitable properties that are identifiable, but we lift this assumption with with our main results in Theorem~\ref{thm:cvx-flats}.

When $\R \subseteq \reals^d$ for some $d \in \mathbb{Z}$, \cite{frongillo2015elicitation} introduce the notion of \emph{(convex) elicitation Complexity}, which uses $d$ to measure the ``efficiency'' of a loss $L$ eliciting $\Gamma$.
However, their notion of complexity relies not just on the property $\Gamma$, but instead on any property \emph{indirectly elicited} by $L$.

\begin{definition}[Indirect Elicitation]\label{def:indirectly-elicits}
	A loss $L$ \emph{indirectly elicits} a property $\gamma:\P \toto \R'$ if it elicits a property $\Gamma: \P\toto \R$ such that there is a function $\psi:\R \to \R'$ such that for all $r \in \R$, we have $\Gamma_r \subseteq \gamma_{\psi(r)}$.
\end{definition}
While there are a few possible definitions of indirect elicitation, this one is the most applicable for our setting because when we consider set-valued properties, we do not have that \emph{all} optimal reports for $\Gamma$ must be linked back to \emph{all} optimal reports for $\gamma$.
Instead, we loosen this restriction to say that any optimal report for $\Gamma$ must be linked to \emph{an} optimal report for $\gamma$, and must be done in a consistent manner.

When properties are vector-valued (i.e.$\, \Gamma: \simplex \to \reals^d$),~\cite{frongillo2015elicitation} introduce the notion of \emph{convex elicitation complexity}.

\begin{definition}[Convex Elicitation Complexity]
	The \emph{convex elicitation complexity} of a property $\eliccvx(\Gamma)$ is the minimum dimension $d$ such that there is a convex loss $L : \reals^d \times \Y \to \reals$ indirectly eliciting $\Gamma$.
\end{definition}

In Proposition~\ref{prop:consistent-implies-indir-elic}, we relate indirect elicitation to the consistency of a surrogate loss.


\subsection{Consistency and calibration for convex losses}\label{subsec:convex-surrogates}
When one starts with a discrete loss they want to minimize or property they want to learn, these are often computationally hard problems.
For this reason, we use surrogate losses to address these difficulties.
However, to measure the effectiveness of a surrogate loss, one needs a link function to map back to the original prediction space; moreover, we would like to map back to the \emph{correct} prediction that would have been given if we had directly optimized the original problem.
This notion of a correct surrogate is captured by two slightly distinct notions introduced here: \emph{consistency} and \emph{calibration}.

\cite{zhang2004statistical,lin2004note,bartlett2006convexity,tewari2007consistency} form a characterization of consistent and calibrated surrogates for classification problems.
In particular,~\cite{bartlett2006convexity} show that if a convex surrogate is differentiable, minimal at $0$, and nonnegative, there is a consistent surrogate for binary classification problems, and ~\cite{tewari2007consistency} generalizes this result for multiclass classification. 
\cite{ramaswamy2016convex} further shows necessary and sufficient conditions for finite prediction problems to be consistent that can be applied to general discrete losses where both the report and outcome set are finite.
\jessie{Left off here}
They additionally introduce a notion of \emph{convex calibration} dimension similar to elicitation complexity mentioned above; we discuss this further in Section~\ref{sec:finite-calib}.
Their calibration results then yield consistent surrogates for finite prediction problems such as hierarchical classification from~\cite{ramaswamy2015hierarchical} and classification with an abstain option studied by~\cite{ramaswamy2018consistent}.

\cite{steinwart2007compare} generalizes the study of consistent losses from the classification setting \ldots \jessiet{Need to come back to this.  area exam Jessie looked at this briefly, but current Jessie is a whole different person.}

While the subtleties of \emph{consistency} vary slightly with each work, we use two definitions that have the same implications, but one may be more appropriate in a given context.

\begin{definition}[Consistent: loss]
	Suppose $f_m : \X \to \R$ is the hypothesis function learned by minimizing empirical training loss over $m$ labeled examples.
	we say a loss and link $(L,\psi)$ are consistent with respect to an original loss $\ell$ if, for all distributions $D$ over input and label spaces $\X \times\Y$, 
	\begin{align*}
	\E_D L(f_m(X), Y) \to \inf_f \E_D L(f(X), Y) &\implies \E_D \ell(\psi \circ f_m(X), Y) \to \inf_f \E_D \ell(\psi \circ f(X), Y)~.~
	\end{align*}
\end{definition}


For continuous properties, such as the expected value, variance, and entropy, asking for a consistent surrogate with respect to an original \emph{loss} may not make sense.
In this setting, we also define consistency with respect to a property. 
\begin{definition}[Consistent: property]
	A loss $L : \reals^d \times \Y \to \reals$ is \emph{$d$-consistent with respect to a property} $\Gamma$ for a metric $d$ if, for all $D$ over $\X \times \Y$,  we observe
\begin{equation}
d(\E_X \Gamma(D_X), \Gamma(D)) \to 0 \implies \E_{(X,Y) \sim D} L(\E_X \Gamma(D_X), Y) \to \inf_{u \in \reals^d} \E_{(X,Y) \sim D} L(u, Y)~,~
\end{equation}
where $\Gamma(D) = \arginf_{u \in \reals^d} \E_D L(u, Y)$.
\end{definition}


\begin{definition}[Excess risk bound]
	A surrogate loss and link pair $(L,\psi)$ satisfies the \emph{excess risk bound} with respect to a loss $\ell$ if there exists an increasing function $\zeta : \reals \to \reals$ that is continuous at $0$ with $\zeta(0) = 0$ so that for all $f:\X \to \R$ and data distributions $D$ over $\X \times \Y$, we have
	\begin{multline}
	\E_{(X,Y) \sim D} \ell(\psi \circ f(X), Y) - \inf_{f^*} \E_{(X,Y) \sim D} \ell(\psi \circ f^*(X), Y) \\ 
	\leq \zeta \left( \E_{(X,Y) \sim D} L(f(X), Y) - \inf_{f^*} \E_{(X,Y) \sim D} L(f^*(X), Y) \right)
	\end{multline}
\end{definition}

\begin{definition}[Calibrated]\label{def:calibrated-general}
	A loss $L:\reals^d \times \Y \to \reals$ is \emph{calibrated} with respect to a property $\gamma : \simplex \toto \R$ elicited by the loss $\ell$ if there is a link $\psi : \reals^d \to \R$ such that, for all distributions $p \in \simplex$, there exists an increasing function $\zeta : \reals \to \reals$ with $\zeta$ continuous at $0$ and $\zeta(0) = 0$ such that for all $u \in \reals^d$, we have
	\begin{equation}
	\ell( \psi(u); p) - \ell(\gamma(p); p)  \leq \zeta \left(  L(u;p) - L(\Gamma(p); p) \right)~.~
	\end{equation}
\end{definition}
\begin{definition}[Calibrated: Finite predictions]\label{def:calibrated-finite}
	Let $\ell : \R \times \Y \to \reals_+$ be a discrete loss eliciting the property $\gamma$.
	A surrogate loss $L : \reals^d \times \Y \to \reals_+$ is \emph{calibrated} with respect to $\ell$ if there exists a link function $\psi: \reals^d \to \R$ such that
	\begin{equation}\label{eq:calibration}
	\forall p \in \simplex: \inf_{u \in \reals^d : \psi(u) \not \in \gamma(p)} L(u;p) > \inf_{u \in \reals^d} L(u;p)~.~
	\end{equation}
\end{definition}

\begin{definition}[Convex Calibration Dimension]
	The \emph{convex calibration dimension} $\ccdim(\ell)$ of a discrete loss $\ell$ is the minimum dimension $d$ such that there is a convex loss $L: \reals^d \times \Y \to \reals$ and link $\psi$ such that $L$ is calibrated with respect to $\ell$.
\end{definition}

\section{Characteristics of Consistent Convex Surrogates}\label{sec:char-convex}

Proposition~\ref{prop:consistent-implies-indir-elic} below allows us to understand the connection between property elicitation and consistent losses.
Moreover, combining Proposition~\ref{prop:consistent-implies-indir-elic} and Theorem~\ref{thm:cvx-flats}, we provide new conditions for finding lower bounds on \emph{convex calibration dimension} for finite outcome settings in Section~\ref{sec:finite-calib}.
In infinite outcome settings, we can generalize Theorem~\ref{thm:cvx-flats}\jessie{hopefully...} in order to answer an open question about convex elicitation complexity posed by~\cite{frongillo2015elicitation}.

\begin{proposition}\label{prop:consistent-implies-indir-elic}
	If a surrogate and link pair $(L, \psi)$ is consistent with respect to $\ell$, then $L$ indirectly elicits $\gamma := \prop{\ell}$.
\end{proposition}


\begin{remark}
	Both definitions of consistency tie to indirect elicitation
\end{remark}

This result allows us to apply the upper bounds from~\cite{frongillo2015elicitation} when trying to find the minimal dimension consistent surrogate for a given loss.
In particular, when $\Y$ is finite and we restrict $L$ to be convex, this translates to applications to \emph{convex calibration dimension} of~\cite{ramaswamy2016convex}.


When one restricts their focus to \emph{convex} surrogates, we know that all minima are global, and we then have $\vec 0  \in \partial L(u, y)$ if and only if $u$ minimizes $L$ in its first component.

%\begin{theorem}
%	Suppose the property $\Gamma$ is elicited by the differentiable, convex loss $L : \reals^d \times \Y \to \reals_+$ such that the infimum $L(\cdot, y)$ is attained for all $y \in \Y$.
%	Then for all $p \in \simplex$, we have $u \in \Gamma(p) \iff \vec 0 \in \nabla_{u'} \inprod{p}{L(u')}$.
%\end{theorem}
%\begin{proof}[Proof sketch]
%	Since $L$ is convex, we know that all minimizers are global. 
%	This implies that $\vec 0 \in \nabla_{u} L(u; p) \iff u \in \arginf_{u'} L(u';p)$, and the latter is true if and only if $u \in \Gamma(p)$ by definition of elicitation.
%\end{proof}
%
%In a large sense, this lets us conclude that $d$-convex elicitable properties are also $d$-identifiable, taking the identification function $V(\cdot;p)$ to be $\nabla_u L(\cdot; p)$ for all $p \in \simplex$.
%\begin{corollary}
%	Suppose the property $\Gamma$ is elicited by the convex loss $L : \reals^d \times \Y \to \reals_+$ such that the infimum $L(\cdot, y)$ is attained for all $y \in \Y$.
%	Then $\Gamma$ is $d$-identifiable.
%\end{corollary}

\begin{definition}[Flat]
	A \emph{flat} $F$ of $\reals^n$ is an affine subspace of $\reals^n$.
	In other words, $F\subseteq \reals^n$ can be written $F=\{x\in\reals^n : Wx + b = 0\}$ for some $W\in\reals^{d\times n}$ and $b\in\reals^d$ where $d\leq n$.
	By the rank-nullity theorem, the dimension of the flat $F$ is the nullity of $W$ by construction, and is given by $f := n - \mathrm{rank}(W)$.
	If $W$ is full-rank, then $f = n - d$.
\end{definition}
Unless otherwise mentioned, we will assume that $W$ is full rank.

Now we can consider specific characteristics of convex losses in order to understand the convex elicitation complexity of a given property.

\begin{theorem}\label{thm:cvx-flats}
	Suppose we are given a property $\gamma$ and distribution $p \in \simplex$.
  \raft{Made logic more direct \jessie{Done?}}
	For all $r\in\gamma(p)$, if there is no $(n - d-1)$-dimensional flat $F$ containing $p$ so that $F \cap \simplex \subseteq \gamma_r$, then there is no convex surrogate loss $L : \reals^d \times \Y \to \reals$ that indirectly elicits $\gamma$.
\end{theorem}



\section{Finite report and outcome settings}\label{sec:finite-calib}


\jessie{Thankfully, \cite{ramaswamy2016convex} has swooped in to save the day with below result. (Original for binary and multiclass classification come from~\cite{bartlett2006convexity} and \cite{tewari2007consistency}, respectively.)}

\begin{theorem}[\cite{ramaswamy2016convex}]\label{thm:calib-iff-consistent}
	If $\Y$ is finite, then the surrogate loss $L:\reals^d \to \reals^\Y_+$ is calibrated with respect to $\ell: \R \times \Y \to \reals_+$ if and only if there exists a link function $\psi : \reals^d \to \R$ such that for all distributions $D$ on $\X \times\Y$ and all sequences of (vector) functions $f_m : \X \to \reals^d$,
	\begin{equation*}
	\E_D L(f_m(X), Y) \to \inf_f \E_P L(f(X), Y) \implies \E_D \ell(\psi  \circ f_m(X), Y) \to \inf_f \E_D \ell(\psi \circ f(X), Y)~.~
	\end{equation*}
\end{theorem}
In words, we have that a surrogate and link are calibrated with respect to a discrete loss if and only if any consistent sequence of hypotheses for the surrogate, when linked, is consistent for the discrete loss.

As calibration does not rely on the representation space $\X$, we can ignore this and focus instead on calibration; we focus on \jessie{marginal} probability distributions $p \in \simplex$, agnostic to $\X$.

\begin{lemma}
	Suppose we are given a discrete loss $\ell : \R \times\Y \to \reals_+$ eliciting the property $\gamma$.
	If $(L, \psi)$ is calibrated with respect to $\ell$, then $L$ indirectly elicits $\gamma$.
\end{lemma}
The proof follows from observing that Theorem~\ref{thm:calib-iff-consistent} yields consistency of $(L,\psi)$ with respect to $\ell$ from calibration, then applying Proposition~\ref{prop:consistent-implies-indir-elic}.


\jessie{Ramaswamy et al introduce FSD as a technique to provide their lower bound...}
\begin{definition}[Subspace of feasible directions]
	Define the \emph{subspace of feasible directions} $\S_\C(p)$ of a convex set $\C \subseteq \reals^n$ at a point $p \in \C$ as the subspace $\S_\C(p) = \{ v \in \reals^n : \exists \epsilon_0 > 0 $ such that $p + \epsilon v \in \C$ and $p - \epsilon v \in \C \; \forall \epsilon \in (0,\epsilon_0) \}$ .
\end{definition}

\begin{lemma}\label{lem:feas-sub-is-a-flat}
	Suppose we have the finite property $\gamma$ and distribution $p \in \simplex$ with $r \in \gamma(p)$.
	If $F$ is a flat containing $p$ such that $F \cap \simplex \subseteq \gamma_r$, then $F - p$ is a subspace contained in $\S_{\gamma_r}(p)$.
\end{lemma}


The following is a statement from~\cite{ramaswamy2016convex} providing an upper bound on the convex calibration dimension of a given discrete loss, which now follows as a Corollary of our Theorem~\ref{thm:cvx-flats} and Lemma~\ref{lem:feas-sub-is-a-flat}.

\begin{corollary}[\cite{ramaswamy2016convex}]
	Suppose we are given a discrete loss $\ell:\R \to \reals^\Y_+$ eliciting $\gamma$.
	Take $p \in \simplex$ and $r \in \R$ such that $p \in \gamma_r$.
	\begin{equation}
	\ccdim(\ell) \geq \|p\|_0 - \dim(\S_{\gamma_r}(p)) - 1~.~
	\end{equation}
\end{corollary}



\jessie{Don't worry about this for now.}
\subsection{Elicitation complexity and convex calibration dimension}
\cite{ramaswamy2016convex} introduces \emph{Convex Calibration Dimension}, which studies the minimal dimension input $d$ to construct a convex surrogate $L : \reals^d \times \Y \to \reals_+$ that is calibrated with respect to a given discrete loss $\ell$, and is similar to elicitaiton complexity as introduced in Definition~\ref{def:elic:cplx}.

Theorem~\ref{thm:calib-iff-consistent} allows us to now relate convex elicitation complexity and convex calibration dimension introduced by~\cite[Definition 10]{ramaswamy2016convex}.
\begin{proposition}
	Consider the discrete loss $\ell : \R \times \Y \to \reals_+$ and $\gamma:= \prop{\ell}$.
	Then $\eliccvx(\gamma) \leq \ccdim(\ell)$.
	\jessie{Need to define $\eliccvx$ and $\ccdim$.}
\end{proposition}


\cite{finocchiaro2019embedding} presents the notion of a surrogate loss \emph{embedding} a discrete loss-- typically by a polyhedral (piecewise linear and convex) surrogate.
If $\gamma$ is the finite property elicited by the discrete loss $\ell$, then for all discrete losses, $\eliccvx(\gamma) \leq \elicpoly(\gamma) \leq \elicembed(\ell)$.
However, one open question that remains from their work is if these bounds are equal. \jessie{\ldots} 



\section{Continuous Properties}\label{sec:contin-consis}
We address one major open question from~\cite{frongillo2015elicitation} by a generalization of Theorem~\ref{thm:cvx-flats}: \emph{what are lower bounds on convex elicitation complexity?}
Proposition~\ref{prop:consistent-implies-indir-elic} allows us to use convex elicitation complexity as a tool to understand efficiency of consistent convex surrogates.

In continuous settings, it is more common to start with a desired property for which we want to construct a consistent surrogate rather than an original loss.
For example, when one wants to learn an $\alpha$-quantile, we start with the property rather than a loss.
In the literature, when one wants to learn a quantile, pinball loss $L(r,y) = (r-y)(\mathbb{1}_{r \geq y} - \alpha)$ typically appears without explanation or justification.
Elicitation allows us to understand why pinball loss is consistent for learning a quantile as the pinball loss elicits the $\alpha$-quantile.



\newpage

\section*{Broader Impact}
\jessie{Now required for NeurIPS, but doesn't count towards page limit.}

\begin{ack}
All the thanks
\end{ack}

\bibliographystyle{plainnat}
\bibliography{diss,extra}

\end{document}
