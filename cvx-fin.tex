\documentclass[11pt]{colt2019}
\usepackage[utf8]{inputenc}
\usepackage{mathtools, amsmath, amssymb, graphicx, verbatim}
%\usepackage[thmmarks, thref, amsthm]{ntheorem}
\usepackage{color}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage[colorinlistoftodos,textsize=tiny]{todonotes} % need xargs for below
%\usepackage{accents}
\usepackage{bbm}
\usepackage{xspace}

\newcommand{\Comments}{1}
\newcommand{\mynote}[2]{\ifnum\Comments=1\textcolor{#1}{#2}\fi}
\newcommand{\mytodo}[2]{\ifnum\Comments=1%
  \todo[linecolor=#1!80!black,backgroundcolor=#1,bordercolor=#1!80!black]{#2}\fi}
\newcommand{\raf}[1]{\mynote{green}{[RF: #1]}}
\newcommand{\raft}[1]{\mytodo{green!20!white}{RF: #1}}
\newcommand{\jessie}[1]{\mynote{purple}{[JF: #1]}}
\newcommand{\jessiet}[1]{\mytodo{purple!20!white}{JF: #1}}
\ifnum\Comments=1               % fix margins for todonotes
  \setlength{\marginparwidth}{1in}
\fi


\newcommand{\reals}{\mathbb{R}}
\newcommand{\posreals}{\reals_{>0}}%{\reals_{++}}

\newcommand{\prop}[1]{\Gamma[#1]}
\newcommand{\eliccvx}{\mathrm{elic}_\mathrm{cvx}}
\newcommand{\elicpoly}{\mathrm{elic}_\mathrm{pcvx}}
\newcommand{\elicembed}{\mathrm{elic}_\mathrm{embed}}

\newcommand{\simplex}{\Delta_\Y}

% alphabetical order, by convention
\newcommand{\D}{\mathcal{D}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}


\newcommand{\inter}[1]{\mathring{#1}}%\mathrm{int}(#1)}
%\newcommand{\expectedv}[3]{\overline{#1}(#2,#3)}
\newcommand{\expectedv}[3]{\E_{Y\sim{#3}} {#1}(#2,Y)}
\newcommand{\toto}{\rightrightarrows}
\newcommand{\strip}{\mathrm{strip}}
\newcommand{\trim}{\mathrm{trim}}
\newcommand{\fplc}{finite-piecewise-linear and convex\xspace} %xspace for use in text
\newcommand{\conv}{\mathrm{conv}}
\newcommand{\ones}{\mathbbm{1}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\arginf}{arg\,inf}
\DeclareMathOperator*{\sgn}{sgn}

%\newtheorem{theorem}{Theorem}
%\newtheorem{lemma}{Lemma}
%\newtheorem{proposition}{Proposition}
%\newtheorem{definition}{Definition}
%\newtheorem{corollary}{Corollary}
%\newtheorem{conjecture}{Conjecture}


\title{Finite Property Convex Elicitation Paper}
\author{Jessie + Raf + Bo}

\begin{document}

\maketitle

\begin{abstract}
  Convex surrogates are sweet.
  Given a loss for a classification-like problem, there are two natural approaches to design convex surrogates.
  First, one may attempt to map each prediction to a low-dimensional vector, and try to find a convex loss in that space with the right calibration.
  Second, one may simply try to find a surrogate within the class of piecewise-linear convex, or polyhedral, losses.
  We show an equivalence between these two approaches, and \raf{more stuff}.
  We show that every loss with a finite number of predictions has a convex surrogate in the above sense using one fewer dimension that the number of outcomes, and give a full characterization of the losses needing only $d$ dimensions for such a surrogate.
  We then apply this characterization to show novel lower bounds for abstain loss, demonstrating the power of our techniques over \raf{check this} alternatives such as feasible subspace dimension.
\end{abstract}

\section{Setting and Background}

\subsection{Notation}
\begin{itemize}
	\item $\Y$ is the finite outcome space, and $n := |\Y|$.
	\item $\simplex\subseteq\reals^\Y$ is the set of distributions over $\Y$, thought of as vectors of probabilities.
	\item For an outcome $y$, we denote $p_y$ as the probability of outcome $y$ being observed in nature.
	\item If $\gamma = \prop{\ell}$, then $\gamma:\simplex \toto \R$ is the property elicited by the loss $\ell: \R \to \reals^\Y$.
	\item $d$ is the dimension of the embedding space
	\item $L:\reals^d \to \reals^\Y$ is a loss taking a report $u \in \reals^d$ and mapping the loss over each outcome in $\Y$. \raf{Changed to $\reals^\Y_+$ below.}
	\item $\Gamma: \simplex \toto \reals^d$ is the set-valued property mapping a probability distribution to a report $u \in \reals^d$.
	\item $\Gamma_u = \{ p \in \simplex : u \in \Gamma(p) \}$
	\item $\psi$ is the link function (see below)
	\item $\varphi:\R \to \reals^d$ is the embedding function
	\item $\trim(\Gamma)$ and $\strip(\Gamma)$
	\item $\eliccvx$, $\elicembed$, and $\elicpoly$
	\item $V$ and $B(P)$ as we get ready for later.
\end{itemize}

\subsection{Properties and Losses}
\begin{definition}
  Property $\Gamma:\simplex\toto\R$

  Level set $\Gamma_r$

\raf{Should bake non-degenerate into the definition: insist that $\Gamma(p) \neq \emptyset$ for all $p$.}
  
  Redundant, finite \raf{I think to avoid a TON of extra mentions of ``non-redundant'' we should take finite to mean finite and non-redundant}
\end{definition}

\begin{definition}
  \raf{I realized that (a) it is common to restrict losses to be non-negative, and (b) it solves some annoying issues where we have to say ``if $L$ is bounded below...'' nicely.  So unless any objections, let's say $L \geq 0$.}
  
  Loss $L:\R\to\reals^\Y_+$, elicits
\end{definition}

\begin{definition}
  Polyhedral function, loss
\end{definition}

\subsection{Link Functions}

\begin{definition}
  Let properties $\gamma:\simplex\toto\R$ and $\Gamma:\simplex\toto\R'$ be given.
  A \emph{link function} is a map $\psi:\R'\to\R$.
  We say that a link $\psi$ is:
  \begin{itemize}
  \item \emph{Calibrated} if for all $p\in\simplex$, $r'\in \Gamma(p) \implies \psi(r') \in \gamma(p)$; in other words, if for all $r'\in\R'$, $\Gamma_{r'} \subseteq \gamma_{\psi(r')}$;
  \item \emph{Separated}, with respect to a loss $L$ eliciting $\Gamma$, if for all $p \in \simplex$, 
  \begin{align*}
  \inf_{u \in \R'; \psi(u) \not \in \gamma(p)} \E_{Y\sim p}[L(u, Y)] > \inf_{u \in \R'}\E_{Y\sim p}[L(u, Y)]
  \end{align*}
  \item \emph{Exhaustive} if for all $p\in\simplex$, $\gamma(p) = \psi(\Gamma(p)) := \{\psi(r') : r'\in\Gamma(p)\}$.
  \end{itemize}
\end{definition}

It is also interesting to contrast the definitions above with the following.
\begin{definition}
  A \emph{strong link} is a function $\psi:\R'\toto\R$ such that for all $p\in\simplex$ and $r'\in\R'$, we have $r'\in\Gamma(p) \implies \gamma(p) = \psi(r')$.
\end{definition}

\raf{We should note here that a discussion like this has not yet appeared in the property elicitation literature, since most papers address direct elicitation, where no link is needed, or single-valued properties in the case of indirect elicitation.  Cite examples for indirect: Frongillo--Kash (NIPS), Fissler--Ziegel (AoS), mode paper, others?}

\raf{Discussion about these definitions using 0-1 loss, hinge, and logistic.  Namely: sign is calibrated for hinge and logistic.  If sign is interpreted as set-valued (0 maps to $\{1,-1\}$, then it is strong for logistic.  If not, sign is not exhaustive for logistic.  Sign is exhaustive for hinge.  It is also separated, but something like $\psi(u) =
  \begin{cases}
    -1 & u \leq -1\\
    1 & u > -1
  \end{cases}$
  would not be, even though it would be calibrated.}


\subsection{Elicitation Complexity}

\begin{definition}
  A loss \emph{indirectly elicits} a property $\gamma$ if it elicits a property with a calibrated link to $\gamma$.
\end{definition}

\raf{Notation up for discussion}
$\eliccvx$ and $\elicpoly$; forward reference $\elicembed$

\subsection{Important Examples}
\raf{Mode, abstain, others?  Mention what is known, especially $\elicpoly($abstain$_{1/2}) \leq \log_2 n$.}

\section{Polyhedral Losses and Embeddings}

\begin{definition}
  A property $\Gamma : \simplex \toto \reals^d$ \emph{embeds} a property $\gamma : \simplex \toto \R$ if there exists some injective embdedding $\varphi:\R\to\reals^d$ such that for all $p\in\simplex,r\in\R$ we have $r \in \gamma(p) \iff \varphi(r) \in \Gamma(p)$.
  Similarly, we say a loss $L:\reals^d\to\reals^\Y$ embeds $\gamma$ if $\prop{L}$ embeds $\gamma$.
  Finally, we say $\gamma$ is \emph{$d$-embeddable}, or just \emph{embeddable}, if such an $L$ exists and is convex.
\end{definition}

% \begin{definition}\label{def:strip-and-trim}
% 	\jessie{strip, trim}
% 	For $\Gamma:\simplex \toto \R'$, define $\strip(\Gamma) = \{\Gamma_r : r \in \R' \}$.
% 	If $\Gamma$ has a finite set of full-dimensional level sets that union to $\simplex$, there is a finite property $\gamma:\simplex \toto \R$ such that $\strip(\gamma) := \trim(\Gamma)$.
% 	\jessie{Fix without over-explaining.}
% \end{definition}

\begin{proposition}\label{prop:optimal-reports-per-level-set}
  \raft{Jessie: I think this should be fine for the paper.  We may want strip and trim for the proof, in the appendix, in which case we can define them there...}
	Let $\Gamma:\simplex\toto\reals^d$ be a non-degenerate (convex) elicitable property.
    \raf{Do we really need $\Gamma$ to be convex elicitable?}
    \jessie{Not a requirement... I threw it in parentheses since we typically think of $\Gamma$ as elicited by a convex surrogate, but it isn't used in the proof.}
	
	The following are equivalent:
	\begin{enumerate}
		\item $\Gamma$ embeds a finite elicitable property $\gamma:\simplex \toto \R$.
		\item The set $\{\Gamma_r : r \in \R \}$ is finite.
		\item There is a finite set of full-dimensional level sets $\Theta$ of $\Gamma$ that union to $\simplex$.
	\end{enumerate}
\end{proposition}
\begin{proof}
For $1 \implies 2$, by definition, if $\gamma$ is finite, then $\R$ is finite.
Thus, the set $\Theta$ generated by indexing a finite set is finite.
For $2 \implies 3$, if any level set is not full-dimensional, it is the subset of a full-dimensional level set, so we can remove it while keeping the property nondegenerate.
Thus, this set $\Theta$ is still finite, consists of full-dimensional level sets, and unions to $\simplex$


For $3 \implies 1$, observe that for each level set $\theta \in \Theta$, there is a report $u \in \reals^d$ such that $\Gamma_u = \theta$.
Let $\R$ be the collection of such reports $u$ corresponding to each $\theta$.
The property $\gamma:p\mapsto \Gamma(p) \cap \R$ is then finite and embedded by $\Gamma$.
To see $\gamma$ is elicitable, consider that each level set of $\gamma$ is also a level set of $\Gamma$, and is therefore convex by the elicitability of $\Gamma$.
Since each level set is convex, we know $\gamma$ is elicitable.
\jessie{Cite?}
\end{proof}

% \begin{proof}
% 	We proceed in a cycle to show $1 \implies 2 \implies 3 \implies 1 $.
% 	\begin{enumerate}
% 		\item [$1 \implies 2$]
% 		We know $\strip(\gamma) = \trim(\Gamma)$ (since $\varphi$ is an injection, and there is some intermediate property $\Gamma'$ such that $\Gamma' \preceq \Gamma$ and with a bijection $\phi:\Gamma'(p) \mapsto \gamma(p)$, so $\strip(\Gamma') = \strip(\gamma)$.) 
% 		As $\gamma$ is finite, so is $\strip(\gamma)$ since strip is generated from the (finite) report set.
		
% 		\item [$2 \implies 3$]
% 		Since $\Gamma$ is nondegenerate and every $\theta \in \trim(\Gamma)$ is full dimensional, it is clear that the union of the level sets of $\trim(\Gamma)$ union to $\simplex$ by nondegneracy of $\Gamma$.
		
% 		\item[$3 \implies 1$]
% 		Construct $\R := \{[u] \in \Gamma(p) : p \in \inter{\theta} \}_{\theta \in \Theta}$.
% 		The property $\gamma: p \mapsto \Gamma(p) \cap\R$ is then finite as $\R$ is finite.
% 		Taking $\varphi$ to be the identity, $\Gamma$ embeds this finite $\gamma$.
% 	\end{enumerate} 
% \end{proof}

\begin{proposition}
  If $\Gamma$ embeds $\gamma$, then there is a link function $\psi$ between $\Gamma$ and $\gamma$.
  Moreover, if $L$ elicits $\Gamma$ and $L$ is polyhedral, $\psi$ can be taken to be separated.
\end{proposition}
\begin{proof}
Let $\varphi$ be the embedding function.
Then the function $\psi(u) := \varphi^{-1}(r)$ is a link between $\Gamma$ and $\gamma$.
Since, for all $p \in\simplex$, we know $\varphi(r) \in \Gamma(p) \implies \varphi^{-1}(\varphi(r)) = r \in \gamma(p)$, we can observe that $\psi$ is a calibrated link.

For the second part, in order for $\psi$ to be separated, for each embedded point $u \in \reals^d$ and every $v \in B(\epsilon, u)$, we must observe $\psi(v) = \psi(u)$.
Suppose $\Gamma$ is elicited by a polyhedral function and the link connecting $\gamma$ and $\Gamma$ was not separated.
Then either the embedded points are too close \jessie{...}.
If, for some $v \in B(\epsilon, u)$, we see $\psi(v) \neq \psi(u)$, then $\psi(v) \neq \psi(w)$ for some $w \neq u$.
\jessie{My brain is turning off and I didn't get to do nearly as much as I thought I was going to be able to tonight, but I'll iterate again in the morning.}
\end{proof}

\begin{theorem}
  Every polyhedral loss embeds a finite elicitable property.
\end{theorem}

\begin{theorem}
  Every finite elicitable property is $(n-1)$-embeddable.
\end{theorem}
\raf{Also mention here that \emph{every} non-redundant elicitable property is $(n-1)$-embeddable.}

\begin{definition}
  Let $\Gamma:\simplex\toto\R$ and $\Gamma':\simplex\toto\R'$.
  Then $\Gamma'$ \emph{refines} $\Gamma$ if for all $r'\in\R'$ we have $\Gamma'_{r'} \subseteq \Gamma_r$ for some $r\in\R$.
  That is, the cells of $\Gamma'$ are all contained in cells of $\Gamma$.
\end{definition}

\begin{theorem}
  A polyhedral loss indirectly elicits a finite elicitable property $\gamma$ if and only if it embeds a property which refines $\gamma$.
\end{theorem}


\section{Embedding Dimension}

\begin{definition}
  The \emph{embedding dimension} of a finite property $\gamma$, written $\elicembed(\gamma)$, is the minimum $d\leq 0$ such that $\gamma$ is $d$-embeddable.
\end{definition}

\subsection{Dimension 1: real-valued losses}

\begin{definition}
  A property $\Gamma:\simplex\to\R$ is \emph{monotone} if there are maps $a:\R\to\reals^\Y$, $b:\R\to\reals^\Y$ and a total ordering $<$ of $\R$ such that the following two conditions hold.
  \begin{enumerate}
  \item For all $r\in\R$, we have $\Gamma_r = \{p\in\simplex : a(r) \cdot p \leq 0 \leq b(r) \cdot p\}$.
  \item For all $r < r'$, we have $a(r) \leq b(r) \leq a(r') \leq b(r')$ (component-wise).
  % \item For all $r,r'\in\R$ and $p\in\Gamma_{r'}\setminus\Gamma_r$, we have $b(r) \cdot p < 0 \implies r' > r$ and $a(r) \cdot p > 0 \implies r' < r$.
  \end{enumerate}
\end{definition}

\raf{From Lambert et al. (2009) -- or maybe this is only in his unpublished paper; need to check}
\begin{definition}
  A finite property $\gamma:\simplex\toto\R$ is \emph{orderable} if there is an enumeration $\R = \{r_1,\ldots,r_k\}$ such that for all $i\in\{1,\ldots,k-1\}$, the intersection $\gamma_{r_i} \cap \gamma_{r_{i+1}}$ is a hyperplane intersected with $\simplex$.
\end{definition}

\begin{lemma}\label{lem:orderable-monotone}
  A finite property is orderable if and only if it is monotone.
\end{lemma}
\begin{proof}
  Let $\gamma:\simplex\toto\R$ be finite and orderable.
  For $1 \leq i < k$, let $v_i\in\reals^\Y$ such that $\gamma_{r_i} \cap \gamma_{r_{i+1}} = \{p\in\simplex : v_i\cdot p = 0\}$.
  As we assume $\gamma$ is non-redundant, we have $p^1 \in \inter\gamma_{r_1}$.
  Without loss of generality, we take the $v_i$ above so that $v_i \cdot p^1 > 0$ for all $i$.
  Now let $b(1) = v_1$ and $a(1) = -\max_y |b(1)_y|\ones$.
  \raf{Really not sure if that is the right start.}
  By our assumptions, $p \in \gamma_1 \iff b(1) \cdot p \geq 0$.
  \raf{Show how to make them monotone... I remember doing this for the continuous convex paper...}

  Conversely, suppose $\gamma:\simplex\toto\R$ be finite and monotone.
  Then we can use the total ordering of $\R$ to write $\R = \{r_1,\ldots,r_k\}$ such that $r_i < r_{i+1}$ for all $i \in \{1,\ldots,k-1\}$.
  We now have $\gamma_{r_i} \cap \gamma_{r_{i+1}} = \{p\in\simplex : a(r_{i+1}) \cdot p \leq 0 \leq b(r_i) \cdot p\}$.
  If this intersection is empty, then there must be some $p$ with $b(r_i) \cdot p < 0$ and $a(r_{i+1}) \cdot p > 0$; by monotonicity, no earlier or later reports can be in $\gamma(p)$, so we see that $\gamma(p) = \emptyset$, a contradiction.
  Thus the intersection is nonempty, and as we also know $b(r_i) \leq a(r_{i+1})$ we conclude $b(r_i) = a(r_{i+1})$, and the intersection is the hyperplane defined by $b(r_i) = a(r_{i+1})$.
\end{proof}

\begin{lemma}\label{lem:prop-L-monotone}
  For any convex loss $L : \reals \to \reals^\Y$, $\prop{L}$ is monotone.
\end{lemma}
\begin{proof}
  Let $a,b$ be defined by $a(r)_y = \partial_- L(r)_y$ and $b(r) = \partial_+ L(r)_y$, that is, the left and right derivatives of $L(\cdot)_y$ at $r$, respectively.
  Then $\partial L(r)_y = [a(r)_y,b(r)_y]$.
  We now have $r \in \prop{L}(p) \iff 0 \in \partial p\cdot L(r) \iff a(r)\cdot p \leq 0 \leq b(r) \cdot p$, showing the first condition.
  The second condition follows as the subgradients of $L$ are monotone functions.
  \raf{More detail and some Rockafellar cites}
\end{proof}

\begin{proposition}\label{prop:indirect-orderable}
  If convex $L : \reals \to \reals^\Y$ indirectly elicits a finite elicitable property $\gamma$, then $\gamma$ is orderable.
\end{proposition}
\begin{proof}
  Let $\gamma:\simplex\toto\R$.
  From Lemma~\ref{lem:prop-L-monotone}, $\prop{L}$ is monotone.
  Let $\psi:\reals\to\R$ be the calibrated link from $\prop{L}$ to $\gamma$.

  \raf{FROM IPAD NOTES}
\end{proof}

\raf{Now follows from the previous and polyhedral $\implies$ embeds}
\begin{corollary}\label{cor:embed-orderable}
  Every polyhedral $L : \reals \to \reals^\Y$ embeds an orderable property.
\end{corollary}

\begin{proposition}
  Every orderable property $\gamma$ is 1-embeddable.
\end{proposition}
\begin{proof}
  Let $\R = \{r_1,\ldots,r_k\}$ be the report space for $\gamma$.
  From Lemma~\ref{lem:prop-L-monotone}, and its proof, we have $a:\R\to\reals^\Y, b\to\reals^\Y$ such that $\gamma_r = \{p\in\simplex : a(r) \cdot p \leq 0 \leq b(r) \cdot p\}$ for all $r\in\R$, and for all $i \in \{1,\ldots,k-1\}$, we have $a(r_i) \leq b(r_i) = a(r_{i+1}) \leq b(r_{i+1})$.
  We now define $\varphi(r_i) = i \in \reals$, and $L$... \raf{integrate?  this should be simple... want $\partial L(i)_y = [a(r_i)_y,b(r_i)_y]$.}
\end{proof}

We can summarize the above in the following theorem.
\begin{theorem}
  Let $\gamma$ be a finite elicitable property.
  Then $\gamma$ is 1-embeddable if and only if it is orderable.
  In particular, if $\eliccvx(\gamma)=1$, then $\elicpoly(\gamma) = \elicembed(\gamma)=1$.
\end{theorem}

\subsection{General dimensions}

\raf{The full characterization; optimality and monotonicity:}
\begin{theorem}
  A finite property $\Gamma:\simplex\toto\R$ is $d$-embeddable if and only if there exists an embedding $\varphi: \R \to \reals^d$ and polytopes $T(r,y) \subseteq \reals^d$ for all $r\in\R, y\in\Y$, such that the following two conditions hold:
  \begin{enumerate}
  \item For all $r\in\R, p\in\simplex$, we have $r\in \Gamma(p) \iff 0 \in \sum_{y\in\Y} p_y T(r,y)$, where summation is the Minkowski sum.
  \item For all $y\in\Y$ there exists some convex function $L_y$ such that for all $r\in\R$ we have $T(r,y) = \partial L_y(\varphi(r))$.
  \end{enumerate}
\end{theorem}

\subsection{Useful necessary conditions}

\begin{corollary}
  \raf{Optimality: Bo's polytope stuff}
\end{corollary}

\begin{corollary}
  \raf{Monotonicity: WMON}
\end{corollary}

\begin{corollary}
  \raf{reduction to 1 dimension}
\end{corollary}

\section{Application: Abstain Loss}

\begin{theorem}
  Abstain with $\alpha=1/2$ and $|\Y|=5$ is not $2$-embeddable.
\end{theorem}

\begin{theorem}
  Abstain with $\alpha > 1/2$ and $|\Y|=7$ is not $2$-embeddable.
\end{theorem}

\begin{conjecture}
  Abstain with $\alpha=1/2$ is $(\log_2 |\Y|)$-embeddable, but no lower.
\end{conjecture}

\section{Conclusion and Future Work}

Let $\mathrm{elic}_{embed}$ denote the elicitation complexity with respect to embeddings, $\mathrm{elic}_{Pcvx}$ the complexity with respect to polyhedral convex losses, and $\mathrm{elic}_{cvx}$ the complexity with respect to arbitrary convex losses.

\begin{conjecture}
  $\mathrm{elic}_{embed}(\Gamma) = \mathrm{elic}_{Pcvx}(\Gamma) = \mathrm{elic}_{cvx}(\Gamma)$ for all finite, elicitable properties $\Gamma$.
\end{conjecture}

\subsection*{Acknowledgements}
We thank Peter Bartlett for several discussions early on, which led to a proof of \raf{1-d reduction} among other insights.

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
