\documentclass[11pt]{colt2019}
\usepackage[utf8]{inputenc}
\usepackage{mathtools, amsmath, amssymb, graphicx, verbatim}
%\usepackage[thmmarks, thref, amsthm]{ntheorem}
\usepackage{color}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage[colorinlistoftodos,textsize=tiny]{todonotes} % need xargs for below
%\usepackage{accents}
\usepackage{bbm}
\usepackage{xspace}

\newcommand{\Comments}{1}
\newcommand{\mynote}[2]{\ifnum\Comments=1\textcolor{#1}{#2}\fi}
\newcommand{\mytodo}[2]{\ifnum\Comments=1%
  \todo[linecolor=#1!80!black,backgroundcolor=#1,bordercolor=#1!80!black]{#2}\fi}
\newcommand{\raf}[1]{\mynote{green}{[RF: #1]}}
\newcommand{\raft}[1]{\mytodo{green!20!white}{RF: #1}}
\newcommand{\jessie}[1]{\mynote{purple}{[JF: #1]}}
\newcommand{\jessiet}[1]{\mytodo{purple!20!white}{JF: #1}}
\ifnum\Comments=1               % fix margins for todonotes
  \setlength{\marginparwidth}{1in}
\fi


\newcommand{\reals}{\mathbb{R}}
\newcommand{\posreals}{\reals_{>0}}%{\reals_{++}}

\newcommand{\prop}[1]{\mathsf{prop}[#1]}
\newcommand{\eliccvx}{\mathrm{elic}_\mathrm{cvx}}
\newcommand{\elicpoly}{\mathrm{elic}_\mathrm{pcvx}}
\newcommand{\elicembed}{\mathrm{elic}_\mathrm{embed}}

\newcommand{\simplex}{\Delta_\Y}

% alphabetical order, by convention
\newcommand{\D}{\mathcal{D}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}


\newcommand{\inter}[1]{\mathring{#1}}%\mathrm{int}(#1)}
%\newcommand{\expectedv}[3]{\overline{#1}(#2,#3)}
\newcommand{\expectedv}[3]{\E_{Y\sim{#3}} {#1}(#2,Y)}
\newcommand{\toto}{\rightrightarrows}
\newcommand{\strip}{\mathrm{strip}}
\newcommand{\trim}{\mathrm{trim}}
\newcommand{\fplc}{finite-piecewise-linear and convex\xspace} %xspace for use in text
\newcommand{\conv}{\mathrm{conv}}
\newcommand{\ones}{\mathbbm{1}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\arginf}{arg\,inf}
\DeclareMathOperator*{\sgn}{sgn}

%\newtheorem{theorem}{Theorem}
%\newtheorem{lemma}{Lemma}
%\newtheorem{proposition}{Proposition}
%\newtheorem{definition}{Definition}
%\newtheorem{corollary}{Corollary}
%\newtheorem{conjecture}{Conjecture}


\title{Finite Property Convex Elicitation Paper}
\author{Jessie + Raf + Bo}

\begin{document}

\maketitle

\begin{abstract}
  Convex surrogates are sweet.
  Given a loss for a classification-like problem, there are two natural approaches to design convex surrogates.
  First, one may attempt to map each prediction to a low-dimensional vector, and try to find a convex loss in that space with the right calibration.
  Second, one may simply try to find a surrogate within the class of piecewise-linear convex, or polyhedral, losses.
  We show an equivalence between these two approaches, and \raf{more stuff}.
  We show that every loss with a finite number of predictions has a convex surrogate in the above sense using one fewer dimension that the number of outcomes, and give a full characterization of the losses needing only $d$ dimensions for such a surrogate.
  We then apply this characterization to show novel lower bounds for abstain loss, demonstrating the power of our techniques over \raf{check this} alternatives such as feasible subspace dimension.
\end{abstract}

\section{Setting and Background}

\subsection{Notation}
\begin{itemize}
	\item $\Y$ is the finite outcome space, and $n := |\Y|$.
	\item $\simplex$ is the set of distributions over $\Y$.
	\item For an outcome $y$, we denote $p_y$ as the probability of outcome $y$ being observed in nature.
	\item If $\gamma = \prop{\ell}$, then $\gamma:\simplex \toto \R$ is the property elicited by the loss $\ell: \R \to \reals^\Y$.
	\item $d$ is the dimension of the embedding space
	\item $L:\reals^d \to \reals^\Y$ is a loss taking a report $u \in \reals^d$ and mapping the loss over each outcome in $\Y$.
	\item $\Gamma: \simplex \toto \reals^d$ is the set-valued property mapping a probability distribution to a report $u \in \reals^d$.
	\item $\Gamma_u = \{ p \in \simplex : u \in \Gamma(p) \}$
	\item $\psi$ is the link function (see below)
	\item $\varphi:\R \to \reals^d$ is the embedding function
	\item $\trim(\Gamma)$ and $\strip(\Gamma)$
	\item $\eliccvx$, $\elicembed$, and $\elicpoly$
	\item $V$ and $B(P)$ as we get ready for later.
\end{itemize}

\subsection{Properties and Losses}
\begin{definition}
  Property $\Gamma:\simplex\toto\R$

  Redundant, finite \raf{I think to avoid a TON of extra mentions of ``non-redundant'' we should take finite to mean finite and non-redundant}
\end{definition}

\begin{definition}
  Loss $L:\R\to\reals^\Y$, elicits
\end{definition}

\begin{definition}
  Polyhedral function, loss
\end{definition}

\subsection{Link Functions}

\begin{definition}
  Let properties $\gamma:\simplex\toto\R$ and $\Gamma:\simplex\toto\R'$ be given.
  A \emph{link function} is a map $\psi:\R'\to\R$.
  We say that a link $\psi$ is:
  \begin{itemize}
  \item \emph{Calibrated} if for all $p\in\simplex$, $r'\in \Gamma(p) \implies \psi(r') \in \gamma(p)$; in other words, if for all $r'\in\R'$, $\Gamma_{r'} \subseteq \gamma_{\psi(r')}$;
  \item \emph{Separated}, with respect to a loss $L$ eliciting $\Gamma$, if \raf{Shivani definition};
  \item \emph{Exhaustive} if for all $p\in\simplex$, $\gamma(p) = \psi(\Gamma(p)) := \{\psi(r') : r'\in\Gamma(p)\}$.
  \end{itemize}
\end{definition}

It is also interesting to contrast the definitions above with the following.
\begin{definition}
  A \emph{strong link} is a function $\psi:\R'\toto\R$ such that for all $p\in\simplex$ and $r'\in\R'$, we have $r'\in\Gamma(p) \implies \gamma(p) = \psi(r')$.
\end{definition}

\raf{We should note here that a discussion like this has not yet appeared in the property elicitation literature, since most papers address direct elicitation, where no link is needed, or single-valued properties in the case of indirect elicitation.  Cite examples for indirect: Frongillo--Kash (NIPS), Fissler--Ziegel (AoS), mode paper, others?}

\raf{Discussion about these definitions using 0-1 loss, hinge, and logistic.  Namely: sign is calibrated for hinge and logistic.  If sign is interpreted as set-valued (0 maps to $\{1,-1\}$, then it is strong for logistic.  If not, sign is not exhaustive for logistic.  Sign is exhaustive for hinge.  It is also separated, but something like $\psi(u) =
  \begin{cases}
    -1 & u \leq -1\\
    1 & u > -1
  \end{cases}$
  would not be, even though it would be calibrated.}


\subsection{Elicitation Complexity}

\raf{Notation up for discussion}
$\eliccvx$ and $\elicpoly$; forward reference $\elicembed$

\subsection{Important Examples}
\raf{Mode, abstain, others?  Mention what is known, especially $\elicpoly($abstain$_{1/2}) \leq \log_2 n$.}

\section{Polyhedral Losses and Embeddings}

\begin{definition}
  Embeds, embeddable

  \raf{I think we want to say $\Gamma$ embeds $\gamma$, and then a loss $L$ embeds $\gamma$ if $\prop{L}$ embeds $\gamma$.}
\end{definition}

\begin{definition}\label{def:strip-and-trim}
	\jessie{strip, trim}
	For $\Gamma:\simplex \toto \R'$, define $\strip(\Gamma) = \{\Gamma_r : r \in \R' \}$.
	If $\Gamma$ has a finite set of full-dimensional level sets that union to $\simplex$, there is a finite property $\gamma:\simplex \toto \R$ such that $\strip(\gamma) := \trim(\Gamma)$.
	\jessie{Fix without over-explaining.}
\end{definition}

\begin{proposition}\label{prop:optimal-reports-per-level-set}
	Let $\Gamma:\simplex\toto\reals^d$ be a non-degenerate (convex) elicitable property.
	
	The following are equivalent:
	\begin{enumerate}
		\item There is a nondegenerate, finite property $\gamma:\simplex\toto\R$ such that there is an injection $\varphi:\R\to\reals^d$ such that $r\in\gamma(p) \iff \varphi(r) \in \Gamma(p)$. (i.e. $\Gamma$ embeds a finite $\gamma$).  
		\item $\trim(\Gamma)$ is finite.     
		\item There is a finite set of full-dimensional level sets $\Theta$ of $\Gamma$ that union to $\simplex$.
		
	\end{enumerate}
\end{proposition}

\begin{proof}
	We proceed in a cycle to show $1 \implies 2 \implies 3 \implies 1 $.
	\begin{enumerate}
		\item [$1 \implies 2$]
		We know $\strip(\gamma) = \trim(\Gamma)$ (since $\varphi$ is an injection, and there is some intermediate property $\Gamma'$ such that $\Gamma' \preceq \Gamma$ and with a bijection $\phi:\Gamma'(p) \mapsto \gamma(p)$, so $\strip(\Gamma') = \strip(\gamma)$.) 
		As $\gamma$ is finite, so is $\strip(\gamma)$ since strip is generated from the (finite) report set.
		
		\item [$2 \implies 3$]
		Since $\Gamma$ is nondegenerate and every $\theta \in \trim(\Gamma)$ is full dimensional, it is clear that the union of the level sets of $\trim(\Gamma)$ union to $\simplex$ by nondegneracy of $\Gamma$.
		
		\item[$3 \implies 1$]
		Construct $\R := \{[u] \in \Gamma(p) : p \in \inter{\theta} \}_{\theta \in \Theta}$.
		The property $\gamma: p \mapsto \Gamma(p) \cap\R$ is then finite as $\R$ is finite.
		Taking $\varphi$ to be the identity, $\Gamma$ embeds this finite $\gamma$.
	\end{enumerate} 
\end{proof}

\begin{proposition}
  If $\Gamma$ embeds $\gamma$, then there is a link function $\psi$ between $\Gamma$ and $\gamma$.
  Moreover, if $L$ elicits $\Gamma$ and $L$ is polyhedral, $\psi$ can be taken to be separated.
\end{proposition}

\begin{theorem}
  Every polyhedral loss embeds a finite elicitable property.
\end{theorem}

\begin{theorem}
  Every finite elicitable property is embeddable.
\end{theorem}

\begin{definition}
  A property refines another
\end{definition}

\begin{theorem}
  A polyhedral loss indirectly elicits a finite elicitable property $\gamma$ if and only if it embeds a property which refines $\gamma$.
\end{theorem}


\section{Embedding Dimension}

\begin{definition}
  $d$-embeddable, $\elicembed$
\end{definition}

\subsection{Dimension 1: real-valued losses}

\begin{definition}
  A property $\Gamma:\simplex\to\R$ is \emph{monotone} if there are maps $a:\R\to\reals^\Y$, $b:\R\to\reals^\Y$ and a total ordering $<$ of $\R$ such that the following two conditions hold.
  \begin{enumerate}
  \item For all $r\in\R$, we have $\Gamma_r = \{p\in\simplex : a(r) \cdot p \leq 0 \leq b(r) \cdot p\}$.
  \item For all $r < r'$, we have $b(r) \leq a(r')$ (component-wise).
  % \item For all $r,r'\in\R$ and $p\in\Gamma_{r'}\setminus\Gamma_r$, we have $b(r) \cdot p < 0 \implies r' > r$ and $a(r) \cdot p > 0 \implies r' < r$.
  \end{enumerate}
\end{definition}

\raf{From Lambert et al. (2009) -- or maybe this is only in his unpublished paper; need to check}
\begin{definition}
  A finite property $\gamma:\simplex\to\R$ is \emph{orderable} if there is an enumeration $\R = \{r_1,\ldots,r_k\}$ such that for all $i\in\{1,\ldots,k-1\}$, the intersection $\gamma_{r_i} \cap \gamma_{r_{i+1}}$ is a hyperplane intersected with $\simplex$.
\end{definition}

\begin{lemma}
  A finite property is orderable if and only if it is monotone.
\end{lemma}

\begin{lemma}
  For any convex loss $L : \reals \to \reals^\Y$, $\prop{L}$ is monotone.
\end{lemma}

\begin{proposition}
  If convex $L : \reals \to \reals^\Y$ indirectly elicits a finite elicitable property $\gamma$, then $\gamma$ is orderable.
\end{proposition}

\raf{Now follows from the previous and polyhedral $\implies$ embeds}
\begin{corollary}
  Every polyhedral $L : \reals \to \reals^\Y$ embeds an orderable property.
\end{corollary}

\begin{proposition}
  Every orderable property $\gamma$ is 1-embeddable.
\end{proposition}

We can summarize the above in the following theorem.
\begin{theorem}
  Let $\gamma$ be a finite elicitable property.
  Then $\gamma$ is 1-embeddable if and only if it is orderable.
  In particular, if $\eliccvx(\gamma)=1$, then $\elicpoly(\gamma) = \elicembed(\gamma)=1$.
\end{theorem}

\subsection{General dimensions}

\raf{Cite the proof of the theorem saying every finite elicitable property is embeddable.}
\begin{corollary}
  Every finite elicitable property is $(n-1)$-embeddable.
\end{corollary}
\raf{Also mention here that \emph{every} non-redundant elicitable property is $(n-1)$-embeddable.}

\raf{The full characterization; optimality and monotonicity:}
\begin{theorem}
  A finite property $\Gamma:\simplex\toto\R$ is $d$-embeddable if and only if there exists an embedding $\varphi: \R \to \reals^d$ and polytopes $T(r,y) \subseteq \reals^d$ for all $r\in\R, y\in\Y$, such that the following two conditions hold:
  \begin{enumerate}
  \item For all $r\in\R, p\in\simplex$, we have $r\in \Gamma(p) \iff 0 \in \sum_{y\in\Y} p_y T(r,y)$, where summation is the Minkowski sum.
  \item For all $y\in\Y$ there exists some convex function $L_y$ such that for all $r\in\R$ we have $T(r,y) = \partial L_y(\varphi(r))$.
  \end{enumerate}
\end{theorem}

\subsection{Useful necessary conditions}

\begin{corollary}
  \raf{Optimality: Bo's polytope stuff}
\end{corollary}

\begin{corollary}
  \raf{Monotonicity: WMON}
\end{corollary}

\begin{corollary}
  \raf{reduction to 1 dimension}
\end{corollary}

\section{Application: Abstain Loss}

\begin{theorem}
  Abstain with $\alpha=1/2$ and $|\Y|=5$ is not $2$-embeddable.
\end{theorem}

\begin{theorem}
  Abstain with $\alpha > 1/2$ and $|\Y|=7$ is not $2$-embeddable.
\end{theorem}

\begin{conjecture}
  Abstain with $\alpha=1/2$ is $(\log_2 |\Y|)$-embeddable, but no lower.
\end{conjecture}

\section{Conclusion and Future Work}

Let $\mathrm{elic}_{embed}$ denote the elicitation complexity with respect to embeddings, $\mathrm{elic}_{Pcvx}$ the complexity with respect to polyhedral convex losses, and $\mathrm{elic}_{cvx}$ the complexity with respect to arbitrary convex losses.

\begin{conjecture}
  $\mathrm{elic}_{embed}(\Gamma) = \mathrm{elic}_{Pcvx}(\Gamma) = \mathrm{elic}_{cvx}(\Gamma)$ for all finite, elicitable properties $\Gamma$.
\end{conjecture}

\subsection*{Acknowledgements}
We thank Peter Bartlett for several discussions early on, which led to a proof of \raf{1-d reduction} among other insights.

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
